{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing dependencies\r\n",
    "from sqlalchemy import create_engine\r\n",
    "from config import db_password\r\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating connection string\r\n",
    "db_string = f\"postgres://postgres:{db_password}@indusscript.cljludlfcgoa.us-east-2.rds.amazonaws.com:5432/postgres\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting Dataframe display to max\r\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating engine\r\n",
    "engine = create_engine(db_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>form</th>\n      <th>lemma</th>\n      <th>upos</th>\n      <th>xpos</th>\n      <th>head</th>\n      <th>FormWithoutLemma</th>\n      <th>NoSpaceAfter</th>\n      <th>Counts</th>\n      <th>MorphemeSeparated</th>\n      <th>index1</th>\n      <th>index2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4000-4001-2017-4003-2017-2000</td>\n      <td>சென்னை</td>\n      <td>N</td>\n      <td>NEN-3SN--</td>\n      <td>2</td>\n      <td></td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>{ச,ெ,ன,்,ன,ை}</td>\n      <td>0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>106</td>\n      <td>அருகே</td>\n      <td>P</td>\n      <td>PP-------</td>\n      <td>18</td>\n      <td></td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>{அ,ர,ு,க,ே}</td>\n      <td>1</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4005-4003-4006-4007</td>\n      <td>ஸ்ரீ</td>\n      <td>N</td>\n      <td>NEN-3SN--</td>\n      <td>4</td>\n      <td></td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>{ஸ,்,ர,ீ}</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2033-4001-4006-4009-4010-4003-2033-4009-2021-4012-4006-2008</td>\n      <td>பெரும்புதூர்</td>\n      <td>N</td>\n      <td>NEL-3SN--</td>\n      <td>18</td>\n      <td>ில்</td>\n      <td>0.0</td>\n      <td>136</td>\n      <td>{ப,ெ,ர,ு,ம,்,ப,ு,த,ூ,ர,ி,ல,்}</td>\n      <td>3</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2025-2037-4006-4007-2017-4003</td>\n      <td>கிரீன்</td>\n      <td>N</td>\n      <td>NEN-3SN--</td>\n      <td>6</td>\n      <td></td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>{க,ி,ர,ீ,ன,்}</td>\n      <td>4</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                                          form         lemma  \\\n0                                4000-4001-2017-4003-2017-2000        சென்னை   \n1                                                          106         அருகே   \n2                                          4005-4003-4006-4007          ஸ்ரீ   \n3  2033-4001-4006-4009-4010-4003-2033-4009-2021-4012-4006-2008  பெரும்புதூர்   \n4                                2025-2037-4006-4007-2017-4003        கிரீன்   \n\n  upos       xpos  head FormWithoutLemma  NoSpaceAfter  Counts  \\\n0    N  NEN-3SN--     2                            0.0       0   \n1    P  PP-------    18                            0.0       0   \n2    N  NEN-3SN--     4                            0.0       0   \n3    N  NEL-3SN--    18              ில்           0.0     136   \n4    N  NEN-3SN--     6                            0.0       0   \n\n               MorphemeSeparated  index1  index2   \n0                  {ச,ெ,ன,்,ன,ை}       0        6  \n1                    {அ,ர,ு,க,ே}       1        5  \n2                      {ஸ,்,ர,ீ}       2        4  \n3  {ப,ெ,ர,ு,ம,்,ப,ு,த,ூ,ர,ி,ல,்}       3       11  \n4                  {க,ி,ர,ீ,ன,்}       4        6  "
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading logosyllabic data\r\n",
    "logosyl_data = pd.read_sql_table('logo_syllabic_tamil', con=engine)\r\n",
    "logosyl_data.drop(columns=\"index\", inplace=True)\r\n",
    "s = logosyl_data.index1.sort_values().index\r\n",
    "logosyl_data = logosyl_data.reindex(s)\r\n",
    "logosyl_data.reset_index(drop=True, inplace=True)\r\n",
    "logosyl_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "8628"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determining number of times to iterate through the dataframe to connect the separated clitics to words\r\n",
    "numberof2 = len(logosyl_data[logosyl_data[\"NoSpaceAfter\"]==2.0])\r\n",
    "numberof3 = len(logosyl_data[logosyl_data[\"NoSpaceAfter\"]==3.0])\r\n",
    "numberofrows = len(logosyl_data)\r\n",
    "iterate = numberofrows - numberof2 - numberof3\r\n",
    "iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167\n",
      "266\n",
      "294\n",
      "2992\n",
      "8627\n"
     ]
    }
   ],
   "source": [
    "# Connecting separated clitics to the words\r\n",
    "for i in range(iterate):\r\n",
    "    try:\r\n",
    "        if logosyl_data.loc[i+1, \"NoSpaceAfter\"]==2.0:\r\n",
    "            if logosyl_data.loc[i+2, \"NoSpaceAfter\"]==2.0:\r\n",
    "                if logosyl_data.loc[i+3, \"NoSpaceAfter\"]==2.0:\r\n",
    "                    if logosyl_data.loc[i+4, \"NoSpaceAfter\"]==2.0:\r\n",
    "                        logosyl_data.loc[i+3, \"form\"] = logosyl_data.loc[i+3, \"form\"] + logosyl_data.loc[i+4, \"form\"]\r\n",
    "                        logosyl_data.drop(i+4, axis=0, inplace=True)\r\n",
    "                        logosyl_data.loc[i+2, \"form\"] = logosyl_data.loc[i+2, \"form\"] + logosyl_data.loc[i+3, \"form\"]\r\n",
    "                        logosyl_data.drop(i+3, axis=0, inplace=True)\r\n",
    "                        logosyl_data.loc[i+1, \"form\"] = logosyl_data.loc[i+1, \"form\"] + logosyl_data.loc[i+2, \"form\"]\r\n",
    "                        logosyl_data.drop(i+2, axis=0, inplace=True)\r\n",
    "                        logosyl_data.loc[i, \"form\"] = logosyl_data.loc[i, \"form\"] + logosyl_data.loc[i+1, \"form\"]\r\n",
    "                        logosyl_data.drop(i+1, axis=0, inplace=True)\r\n",
    "                        logosyl_data.reset_index(drop=True, inplace=True)\r\n",
    "                        \r\n",
    "                    else:\r\n",
    "                        logosyl_data.loc[i+2, \"form\"] = logosyl_data.loc[i+2, \"form\"] + logosyl_data.loc[i+3, \"form\"]\r\n",
    "                        logosyl_data.drop(i+3, axis=0, inplace=True)\r\n",
    "                        logosyl_data.loc[i+1, \"form\"] = logosyl_data.loc[i+1, \"form\"] + logosyl_data.loc[i+2, \"form\"]\r\n",
    "                        logosyl_data.drop(i+2, axis=0, inplace=True)\r\n",
    "                        logosyl_data.loc[i, \"form\"] = logosyl_data.loc[i, \"form\"] + logosyl_data.loc[i+1, \"form\"]\r\n",
    "                        logosyl_data.drop(i+1, axis=0, inplace=True)\r\n",
    "                        logosyl_data.reset_index(drop=True, inplace=True)\r\n",
    "                else:\r\n",
    "                    logosyl_data.loc[i+1, \"form\"] = logosyl_data.loc[i+1, \"form\"] + logosyl_data.loc[i+2, \"form\"]\r\n",
    "                    logosyl_data.drop(i+2, axis=0, inplace=True)\r\n",
    "                    logosyl_data.loc[i, \"form\"] = logosyl_data.loc[i, \"form\"] + logosyl_data.loc[i+1, \"form\"]\r\n",
    "                    logosyl_data.drop(i+1, axis=0, inplace=True)\r\n",
    "                    logosyl_data.reset_index(drop=True, inplace=True)\r\n",
    "            else:\r\n",
    "                logosyl_data.loc[i, \"form\"] = logosyl_data.loc[i, \"form\"] + logosyl_data.loc[i+1, \"form\"]\r\n",
    "                logosyl_data.drop(i+1, axis=0, inplace=True)\r\n",
    "                logosyl_data.reset_index(drop=True, inplace=True)\r\n",
    "        elif logosyl_data.loc[i, \"NoSpaceAfter\"]==3.0:\r\n",
    "            logosyl_data.loc[i, \"form\"] = logosyl_data.loc[i, \"form\"] + logosyl_data.loc[i+1, \"form\"]\r\n",
    "            logosyl_data.drop(i+1, axis=0, inplace=True)\r\n",
    "            logosyl_data.reset_index(drop=True, inplace=True)\r\n",
    "            print(i)\r\n",
    "    except KeyError:\r\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating sentences dataframe\r\n",
    "sentence_df = pd.DataFrame(columns=['Sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the words into sentences\r\n",
    "sentence = []\r\n",
    "j = 0\r\n",
    "for i in range(len(logosyl_data[\"form\"])):\r\n",
    "    if logosyl_data.loc[i, \"xpos\"]!= 'Z#-------':\r\n",
    "        sentence.append(logosyl_data.loc[i, \"form\"])\r\n",
    "    else:\r\n",
    "        sentence.append(logosyl_data.loc[i, \"form\"])\r\n",
    "        sentencestring = \" \".join(sentence)\r\n",
    "        sentence_df.loc[j, \"Sentence\"] = sentencestring\r\n",
    "        sentence=[]\r\n",
    "        j = j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4000-4001-2017-4003-2017-2000 106 4005-4003-4006-4007 2033-4001-4006-4009-4010-4003-2033-4009-2021-4012-4006-2008 2025-2037-4006-4007-2017-4003 2033-4007-4015-4003-4016-4009 ( 5000 ) 5001 5002-2006-2001-2001-155 5003 4017-2028-4006-4009-2001-4010-4003 5004 85 5005-3003-2008 5006-3004 5007-3005 98 5008 2025-4006-4009-4019-2028-4020-2037-2021-2037 5009-2021-47 .</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>559 5011-3006 , 625 5012 5013-2022 5014 : .</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5015 11 5001-3008 5016-2008 5017-3009 5018-3005 5019-3003-2000-2025 5020-2008 5021-3010 , 5022 5023-3011-2012-2008 -107 5001 5002-3011-2012-2000 5024-3012-149 , 5025-3006 5026 5001 5002-3011-2012-2000 5027-3013-149 5028 5029 5030 5031-2021-2006 .</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5032 , 2033-4009-2021-4009-2021-2037-4015-4003-4015-2037 , 4010-4009-4010-4003-2033-2000 , 2025-4021-4015-4003-2025-2021-4003-2021-2028 , 4000-4001-2017-4003-2017-2000 5033-2020 5001 5002-3011-2012-2000 5034 5035 5036-3011-2012 5037-3016-100 5038-3008 5007-2035-2017 .</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>880-2021-4003-2021-2008-149 , 5039-2021-2008-149 2025-2037-4006-4007-2017-4003 2033-4007-4015-4003-4016-4009 5001 5002-3011-2012-2000 5027-2006 500-2021-4003-2021-2000 5040-3019 5021-3020-2039 5041-2022-2017-2034 .</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                                                                                                                                                                                                                                                                                                                                                     Sentence\n0  4000-4001-2017-4003-2017-2000 106 4005-4003-4006-4007 2033-4001-4006-4009-4010-4003-2033-4009-2021-4012-4006-2008 2025-2037-4006-4007-2017-4003 2033-4007-4015-4003-4016-4009 ( 5000 ) 5001 5002-2006-2001-2001-155 5003 4017-2028-4006-4009-2001-4010-4003 5004 85 5005-3003-2008 5006-3004 5007-3005 98 5008 2025-4006-4009-4019-2028-4020-2037-2021-2037 5009-2021-47 .\n1                                                                                                                                                                                                                                                                                                                                 559 5011-3006 , 625 5012 5013-2022 5014 : .\n2                                                                                                                      5015 11 5001-3008 5016-2008 5017-3009 5018-3005 5019-3003-2000-2025 5020-2008 5021-3010 , 5022 5023-3011-2012-2008 -107 5001 5002-3011-2012-2000 5024-3012-149 , 5025-3006 5026 5001 5002-3011-2012-2000 5027-3013-149 5028 5029 5030 5031-2021-2006 .\n3                                                                                                5032 , 2033-4009-2021-4009-2021-2037-4015-4003-4015-2037 , 4010-4009-4010-4003-2033-2000 , 2025-4021-4015-4003-2025-2021-4003-2021-2028 , 4000-4001-2017-4003-2017-2000 5033-2020 5001 5002-3011-2012-2000 5034 5035 5036-3011-2012 5037-3016-100 5038-3008 5007-2035-2017 .\n4                                                                                                                                                      880-2021-4003-2021-2008-149 , 5039-2021-2008-149 2025-2037-4006-4007-2017-4003 2033-4007-4015-4003-4016-4009 5001 5002-3011-2012-2000 5027-2006 500-2021-4003-2021-2000 5040-3019 5021-3020-2039 5041-2022-2017-2034 ."
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Looking at sentences dataframe\r\n",
    "sentence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sending logosyllabic sentences to sql\r\n",
    "sentence_df.to_sql(name ='logo_syllabic_tamil_sentences', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sending logosyllabic sentences to csv\r\n",
    "sentence_df.to_csv('Converted_Tamil/logo_syllabic_tamil_sentences.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>form</th>\n      <th>lemma</th>\n      <th>upos</th>\n      <th>xpos</th>\n      <th>head</th>\n      <th>FormWithoutLemma</th>\n      <th>NoSpaceAfter</th>\n      <th>Counts</th>\n      <th>MorphemeSeparated</th>\n      <th>index1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>சென்னை</td>\n      <td>சென்னை</td>\n      <td>N</td>\n      <td>NEN-3SN--</td>\n      <td>2</td>\n      <td></td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>{ச,ெ,ன,்,ன,ை}</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>அருகே</td>\n      <td>அருகே</td>\n      <td>P</td>\n      <td>PP-------</td>\n      <td>18</td>\n      <td></td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>{அ,ர,ு,க,ே}</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ஸ்ரீ</td>\n      <td>ஸ்ரீ</td>\n      <td>N</td>\n      <td>NEN-3SN--</td>\n      <td>4</td>\n      <td></td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>{ஸ,்,ர,ீ}</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>பெரும்புதூரில்</td>\n      <td>பெரும்புதூர்</td>\n      <td>N</td>\n      <td>NEL-3SN--</td>\n      <td>18</td>\n      <td>ில்</td>\n      <td>0.0</td>\n      <td>136</td>\n      <td>{ப,ெ,ர,ு,ம,்,ப,ு,த,ூ,ர,ி,ல,்}</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>கிரீன்</td>\n      <td>கிரீன்</td>\n      <td>N</td>\n      <td>NEN-3SN--</td>\n      <td>6</td>\n      <td></td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>{க,ி,ர,ீ,ன,்}</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "             form         lemma upos       xpos  head FormWithoutLemma  \\\n0          சென்னை        சென்னை    N  NEN-3SN--     2                    \n1           அருகே         அருகே    P  PP-------    18                    \n2            ஸ்ரீ          ஸ்ரீ    N  NEN-3SN--     4                    \n3  பெரும்புதூரில்  பெரும்புதூர்    N  NEL-3SN--    18              ில்   \n4          கிரீன்        கிரீன்    N  NEN-3SN--     6                    \n\n   NoSpaceAfter  Counts              MorphemeSeparated  index1  \n0           0.0       0                  {ச,ெ,ன,்,ன,ை}       0  \n1           0.0       0                    {அ,ர,ு,க,ே}       1  \n2           0.0       0                      {ஸ,்,ர,ீ}       2  \n3           0.0     136  {ப,ெ,ர,ு,ம,்,ப,ு,த,ூ,ர,ி,ல,்}       3  \n4           0.0       0                  {க,ி,ர,ீ,ன,்}       4  "
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating sentences with original words\r\n",
    "tamildata = pd.read_sql_table('complete_tamil', con=engine)\r\n",
    "tamildata.drop(columns=\"index\", inplace=True)\r\n",
    "s = tamildata.index1.sort_values().index\r\n",
    "tamildata = tamildata.reindex(s)\r\n",
    "tamildata.reset_index(drop=True, inplace=True)\r\n",
    "tamildata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167\n",
      "266\n",
      "294\n",
      "2992\n",
      "8627\n"
     ]
    }
   ],
   "source": [
    "# Connecting separated clitics to the words\r\n",
    "for i in range(iterate):\r\n",
    "    try:\r\n",
    "        if tamildata.loc[i+1, \"NoSpaceAfter\"]==2.0:\r\n",
    "            if tamildata.loc[i+2, \"NoSpaceAfter\"]==2.0:\r\n",
    "                if tamildata.loc[i+3, \"NoSpaceAfter\"]==2.0:\r\n",
    "                    if tamildata.loc[i+4, \"NoSpaceAfter\"]==2.0:\r\n",
    "                        tamildata.loc[i+3, \"form\"] = tamildata.loc[i+3, \"form\"] + tamildata.loc[i+4, \"form\"]\r\n",
    "                        tamildata.drop(i+4, axis=0, inplace=True)\r\n",
    "                        tamildata.loc[i+2, \"form\"] = tamildata.loc[i+2, \"form\"] + tamildata.loc[i+3, \"form\"]\r\n",
    "                        tamildata.drop(i+3, axis=0, inplace=True)\r\n",
    "                        tamildata.loc[i+1, \"form\"] = tamildata.loc[i+1, \"form\"] + tamildata.loc[i+2, \"form\"]\r\n",
    "                        tamildata.drop(i+2, axis=0, inplace=True)\r\n",
    "                        tamildata.loc[i, \"form\"] = tamildata.loc[i, \"form\"] + tamildata.loc[i+1, \"form\"]\r\n",
    "                        tamildata.drop(i+1, axis=0, inplace=True)\r\n",
    "                        tamildata.reset_index(drop=True, inplace=True)\r\n",
    "                        \r\n",
    "                    else:\r\n",
    "                        tamildata.loc[i+2, \"form\"] = tamildata.loc[i+2, \"form\"] + tamildata.loc[i+3, \"form\"]\r\n",
    "                        tamildata.drop(i+3, axis=0, inplace=True)\r\n",
    "                        tamildata.loc[i+1, \"form\"] = tamildata.loc[i+1, \"form\"] + tamildata.loc[i+2, \"form\"]\r\n",
    "                        tamildata.drop(i+2, axis=0, inplace=True)\r\n",
    "                        tamildata.loc[i, \"form\"] = tamildata.loc[i, \"form\"] + tamildata.loc[i+1, \"form\"]\r\n",
    "                        tamildata.drop(i+1, axis=0, inplace=True)\r\n",
    "                        tamildata.reset_index(drop=True, inplace=True)\r\n",
    "                else:\r\n",
    "                    tamildata.loc[i+1, \"form\"] = tamildata.loc[i+1, \"form\"] + tamildata.loc[i+2, \"form\"]\r\n",
    "                    tamildata.drop(i+2, axis=0, inplace=True)\r\n",
    "                    tamildata.loc[i, \"form\"] = tamildata.loc[i, \"form\"] + tamildata.loc[i+1, \"form\"]\r\n",
    "                    tamildata.drop(i+1, axis=0, inplace=True)\r\n",
    "                    tamildata.reset_index(drop=True, inplace=True)\r\n",
    "            else:\r\n",
    "                tamildata.loc[i, \"form\"] = tamildata.loc[i, \"form\"] + tamildata.loc[i+1, \"form\"]\r\n",
    "                tamildata.drop(i+1, axis=0, inplace=True)\r\n",
    "                tamildata.reset_index(drop=True, inplace=True)\r\n",
    "        elif tamildata.loc[i, \"NoSpaceAfter\"]==3.0:\r\n",
    "            tamildata.loc[i, \"form\"] = tamildata.loc[i, \"form\"] + tamildata.loc[i+1, \"form\"]\r\n",
    "            tamildata.drop(i+1, axis=0, inplace=True)\r\n",
    "            tamildata.reset_index(drop=True, inplace=True)\r\n",
    "            print(i)\r\n",
    "    except KeyError:\r\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating sentences dataframe\r\n",
    "sentence_df = pd.DataFrame(columns=['Sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the words into sentences\r\n",
    "sentence = []\r\n",
    "j = 0\r\n",
    "for i in range(len(tamildata[\"form\"])):\r\n",
    "    if tamildata.loc[i, \"xpos\"]!= 'Z#-------':\r\n",
    "        sentence.append(tamildata.loc[i, \"form\"])\r\n",
    "    else:\r\n",
    "        sentence.append(tamildata.loc[i, \"form\"])\r\n",
    "        sentencestring = \" \".join(sentence)\r\n",
    "        sentence_df.loc[j, \"Sentence\"] = sentencestring\r\n",
    "        sentence=[]\r\n",
    "        j = j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>சென்னை அருகே ஸ்ரீ பெரும்புதூரில் கிரீன் பீல்டு ( நவீன ) விமான நிலையத்துக்குக்க்ஆன நிலம் யாருக்கும் பாதிப்பு இல்லாத வகையில் எடுக்கப் படும் என்று முதல்வர் கருணாநிதி உறுதியளித்த்உள்ளார் .</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>இது தொடர்பாக , அவர் புதன்கிழமை வெளியிட்ட அறிக்கை : .</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>நாடு முழுவதும் விமானப் போக்குவரத்தில் ஏற்பட்டு வரும் வளர்ச்சியைக் கருத்தில் கொண்டு , முக்கிய நகரங்களில் உள்ள விமான நிலையங்களை விரிவுபடுத்தவ்உம் , புதிதாக சர்வதேச விமான நிலையங்களை அமைக்கவ்உம் மத்திய அரசு முடிவு செய்தது .</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>அதன்படி , புதுதில்லி , மும்பை , கொல்கத்தா , சென்னை ஆகிய விமான நிலையங்களை மேம்படுத்த புதிய திட்டங்கள் உருவாக்கப்பட்டு நிறைவேற்றப் படுகின்றன .</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>கர்நாடகத்தில்உம் , ஆந்திரத்தில்உம் கிரீன் பீல்டு விமான நிலையங்களை அமைத்து தமிழகத்தை முந்திக் கொண்டு விட்டனர் .</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                                                                                                                                                                                                      Sentence\n0                                     சென்னை அருகே ஸ்ரீ பெரும்புதூரில் கிரீன் பீல்டு ( நவீன ) விமான நிலையத்துக்குக்க்ஆன நிலம் யாருக்கும் பாதிப்பு இல்லாத வகையில் எடுக்கப் படும் என்று முதல்வர் கருணாநிதி உறுதியளித்த்உள்ளார் .\n1                                                                                                                                                                         இது தொடர்பாக , அவர் புதன்கிழமை வெளியிட்ட அறிக்கை : .\n2  நாடு முழுவதும் விமானப் போக்குவரத்தில் ஏற்பட்டு வரும் வளர்ச்சியைக் கருத்தில் கொண்டு , முக்கிய நகரங்களில் உள்ள விமான நிலையங்களை விரிவுபடுத்தவ்உம் , புதிதாக சர்வதேச விமான நிலையங்களை அமைக்கவ்உம் மத்திய அரசு முடிவு செய்தது .\n3                                                                                 அதன்படி , புதுதில்லி , மும்பை , கொல்கத்தா , சென்னை ஆகிய விமான நிலையங்களை மேம்படுத்த புதிய திட்டங்கள் உருவாக்கப்பட்டு நிறைவேற்றப் படுகின்றன .\n4                                                                                                               கர்நாடகத்தில்உம் , ஆந்திரத்தில்உம் கிரீன் பீல்டு விமான நிலையங்களை அமைத்து தமிழகத்தை முந்திக் கொண்டு விட்டனர் ."
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Looking at sentences dataframe\r\n",
    "sentence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Table 'tamil_sentences' already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-f225f8a7b6ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Sending tamil sentences to sql\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msentence_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'tamil_sentences'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2603\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msql\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2605\u001b[1;33m         sql.to_sql(\n\u001b[0m\u001b[0;32m   2606\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2607\u001b[0m             \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m    587\u001b[0m         )\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m     pandas_sql.to_sql(\n\u001b[0m\u001b[0;32m    590\u001b[0m         \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   1391\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1392\u001b[0m         )\n\u001b[1;32m-> 1393\u001b[1;33m         \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1395\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0msqlalchemy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mif_exists\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"fail\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 723\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Table '{self.name}' already exists.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    724\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mif_exists\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpd_sql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Table 'tamil_sentences' already exists."
     ]
    }
   ],
   "source": [
    "#Sending tamil sentences to sql\r\n",
    "sentence_df.to_sql(name ='tamil_sentences', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sending logosyllabic sentences to csv\r\n",
    "sentence_df.to_csv('tamil_sentences.csv', encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python385jvsc74a57bd0acf47b83519c56191d0c3841e12beeb775e3446d2e4f4edc07386d3a55ce7a5e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}