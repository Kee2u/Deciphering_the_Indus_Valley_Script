{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: delayed in c:\\users\\keetu\\anaconda3\\lib\\site-packages (0.11.0b1)\n",
      "Requirement already satisfied: hiredis in c:\\users\\keetu\\anaconda3\\lib\\site-packages (from delayed) (2.0.0)\n",
      "Requirement already satisfied: redis in c:\\users\\keetu\\anaconda3\\lib\\site-packages (from delayed) (3.5.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing dependencies\r\n",
    "from sqlalchemy import create_engine\r\n",
    "from config import db_password\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from numpy.random import normal\r\n",
    "from numpy import hstack\r\n",
    "from numpy import asarray\r\n",
    "from numpy import exp\r\n",
    "from sklearn.neighbors import KernelDensity\r\n",
    "import numpy as np\r\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\r\n",
    "from imblearn.metrics import classification_report_imbalanced\r\n",
    "from imblearn.over_sampling import RandomOverSampler\r\n",
    "from numpy import asarray\r\n",
    "from sklearn.datasets import make_multilabel_classification\r\n",
    "from keras.models import Sequential\r\n",
    "from keras.layers import Dense\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating connection string\r\n",
    "db_string = f\"postgres://postgres:{db_password}@indusscript.cljludlfcgoa.us-east-2.rds.amazonaws.com:5432/postgres\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting Dataframe display to max\r\n",
    "pd.set_option('display.max_rows', None)\r\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating engine\r\n",
    "engine = create_engine(db_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000-5001 1094 5177-5002 5003-5004-5178-5005-5006-4034-4008 5007-5002-4017 5008-5181-4039 ( 2000 ) 2001 2002-4006-4001-4001-1155 2003 5011-5004-4001-5178 2004 1060 2005-5182-4008 2006-4025-4033 2007-5178 1103 2008 4025-5004-5012-5013-5014 2009-4021-1040 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2559 2011-5131 , 2625 2012 2013-4022 2014 : .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015 1014 2001-4033 2016-4008 2017-4039 2018-5178 2019-5182-4000-4025 2020-4008 2021-5186-4039 , 2022 2023-5187-4012-4008 1115 2001 2002-5187-4012-4000 2024-4031-1138 , 2025-5131 2026 2001 2002-5187-4012-4000 2027-4025-4031-1138 2028 2029 2030 2031-4021-4006 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2032 , 5005-4006-5014-5015 , 5016-5178-5017 , 5018-5181-4025-5019 , 5000-5001 2033-4020 2001 2002-5187-4012-4000 2034 2035 2036-5187-4012 2037-4025-4033-1090 2038-4033 2007-4035-4017 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2880-4021-4008-1138 , 2039-4021-4008-1138 5007-5002-4017 5008-5181-4039 2001 2002-5187-4012-4000 2027-4006 2500-4021-4000 2040-5133 2021-5186-4039 2041-4022-4017-4034 .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                               Sentence\n",
       "0       5000-5001 1094 5177-5002 5003-5004-5178-5005-5006-4034-4008 5007-5002-4017 5008-5181-4039 ( 2000 ) 2001 2002-4006-4001-4001-1155 2003 5011-5004-4001-5178 2004 1060 2005-5182-4008 2006-4025-4033 2007-5178 1103 2008 4025-5004-5012-5013-5014 2009-4021-1040 .\n",
       "1                                                                                                                                                                                                                         2559 2011-5131 , 2625 2012 2013-4022 2014 : .\n",
       "2  2015 1014 2001-4033 2016-4008 2017-4039 2018-5178 2019-5182-4000-4025 2020-4008 2021-5186-4039 , 2022 2023-5187-4012-4008 1115 2001 2002-5187-4012-4000 2024-4031-1138 , 2025-5131 2026 2001 2002-5187-4012-4000 2027-4025-4031-1138 2028 2029 2030 2031-4021-4006 .\n",
       "3                                                                              2032 , 5005-4006-5014-5015 , 5016-5178-5017 , 5018-5181-4025-5019 , 5000-5001 2033-4020 2001 2002-5187-4012-4000 2034 2035 2036-5187-4012 2037-4025-4033-1090 2038-4033 2007-4035-4017 .\n",
       "4                                                                                              2880-4021-4008-1138 , 2039-4021-4008-1138 5007-5002-4017 5008-5181-4039 2001 2002-5187-4012-4000 2027-4006 2500-4021-4000 2040-5133 2021-5186-4039 2041-4022-4017-4034 ."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading logosyllabic sentences data from postgreSQL\r\n",
    "logosyllabic_sentence_df = pd.read_sql_table('logo_syllabic_tamil_sentences', con=engine)\r\n",
    "logosyllabic_sentence_df.drop(columns=\"index\", inplace=True)\r\n",
    "logosyllabic_sentence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = ['0','1','2','3','4','5','6','7','8','9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Position</th>\n",
       "      <th>Index</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Sentence, Position, Index, Word]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sign_position_df = pd.DataFrame(columns =['Sentence', 'Position', 'Index', 'Word'])\r\n",
    "sign_position_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "for l in range(len(logosyllabic_sentence_df[\"Sentence\"])):\r\n",
    "    count = 0\r\n",
    "    indexes =[]\r\n",
    "    try:\r\n",
    "        for i in range(len(logosyllabic_sentence_df.loc[l, \"Sentence\"])):\r\n",
    "            if (logosyllabic_sentence_df.loc[l, \"Sentence\"][i] in numbers) and (logosyllabic_sentence_df.loc[l, \"Sentence\"][i+1] in numbers) and (logosyllabic_sentence_df.loc[l, \"Sentence\"][i-1] not in numbers):\r\n",
    "                count = count+1\r\n",
    "                length = len(sign_position_df)\r\n",
    "                sign_position_df.loc[length, \"Sentence\"] = l\r\n",
    "                sign_position_df.loc[length, \"Position\"] = count\r\n",
    "                sign_position_df.loc[length, \"Index\"] = i\r\n",
    "                letter =[]\r\n",
    "                for k in range(6):\r\n",
    "                    if logosyllabic_sentence_df.loc[l, \"Sentence\"][i+k] in numbers:\r\n",
    "                        letter.append(logosyllabic_sentence_df.loc[l, \"Sentence\"][i+k])\r\n",
    "                    else:\r\n",
    "                        word = ''.join(letter)\r\n",
    "                        #print(word)\r\n",
    "                        sign_position_df.loc[length, \"Word\"] = word\r\n",
    "    except:\r\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_position_df[\"MINP\"]=0\r\n",
    "sign_position_df[\"MAXP\"]=0\r\n",
    "sign_position_df[\"AVGP\"]=0\r\n",
    "sign_position_df[\"W\"]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-da98fbc963c6>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sliced_df[\"index\"]=sliced_df.index\n",
      "C:\\Users\\keetu\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Users\\keetu\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(logosyllabic_sentence_df)-1):\r\n",
    "    sliced_df = sign_position_df[sign_position_df[\"Sentence\"]==i]\r\n",
    "    sliced_df[\"index\"]=sliced_df.index\r\n",
    "    sliced_df.reset_index(drop=True, inplace=True)\r\n",
    "    L = sliced_df.loc[(len(sliced_df)-1), \"Position\"]\r\n",
    "    NL = 10\r\n",
    "    W = L/NL\r\n",
    "    sliced_df.loc[:, \"MINP\"] = (sliced_df.loc[:, \"Position\"]-1)*NL/L\r\n",
    "    sliced_df.loc[:, \"MAXP\"] = (sliced_df.loc[:, \"Position\"]*NL/L)\r\n",
    "    sliced_df.W = W\r\n",
    "    mask = sliced_df[\"index\"]\r\n",
    "    sliced_df.index=sliced_df[\"index\"]\r\n",
    "    sign_position_df.loc[mask, [\"MINP\", \"MAXP\", \"W\"]]= sliced_df.loc[:, [\"MINP\", \"MAXP\", \"W\"]]\r\n",
    "\r\n",
    "sign_position_df['AVGP'] = sign_position_df[['MINP', 'MAXP']].mean(axis=1)\r\n",
    "sign_position_df.AVGP = sign_position_df.AVGP.apply(lambda x: round(x))\r\n",
    "sign_position_df.MINP = sign_position_df.MINP.apply(lambda x: round(x))\r\n",
    "sign_position_df.MAXP = sign_position_df.MAXP.apply(lambda x: round(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>AVGP</th>\n",
       "      <th>W</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3536</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Word  AVGP    W  Probability\n",
       "0  3536     0  0.0          NaN"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sign_position_df[\"Word\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating probability distribution as features of Machine Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Word, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
       "Index: []"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df = pd.DataFrame(columns=['Word', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10'])\r\n",
    "word_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sign_position_df)):\r\n",
    "    try:\r\n",
    "        temp_df = sign_position_df[sign_position_df[\"Word\"]==words[i]]\r\n",
    "        temp_df.reset_index(drop=True, inplace=True)\r\n",
    "        hist_df = temp_df[['Word','AVGP','W']].groupby(by=[\"Word\",\"AVGP\"]).sum()\r\n",
    "        hist_df.reset_index(inplace=True)\r\n",
    "        hist_df[\"Probability\"] = hist_df[\"W\"]/sum(hist_df[\"W\"])\r\n",
    "        \r\n",
    "        length = len(word_df)\r\n",
    "        word_df.loc[length, \"Word\"] = hist_df.loc[0, \"Word\"]\r\n",
    "\r\n",
    "        try:\r\n",
    "            word_df.loc[length, \"0\"] = hist_df.loc[0, \"Probability\"]\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "        try:\r\n",
    "            word_df.loc[length, \"1\"] = hist_df.loc[1, \"Probability\"]\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "        try:\r\n",
    "            word_df.loc[length, \"2\"] = hist_df.loc[2, \"Probability\"]\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "        try:\r\n",
    "            word_df.loc[length, \"3\"] = hist_df.loc[3, \"Probability\"]\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "        try:\r\n",
    "            word_df.loc[length, \"4\"] = hist_df.loc[4, \"Probability\"]\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "        try:\r\n",
    "            word_df.loc[length, \"5\"] = hist_df.loc[5, \"Probability\"]\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "        try:\r\n",
    "            word_df.loc[length, \"6\"] = hist_df.loc[6, \"Probability\"]\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "        try:\r\n",
    "            word_df.loc[length, \"7\"] = hist_df.loc[7, \"Probability\"]\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "        try:\r\n",
    "            word_df.loc[length, \"8\"] = hist_df.loc[8, \"Probability\"]\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "        try:\r\n",
    "            word_df.loc[length, \"9\"] = hist_df.loc[9, \"Probability\"]\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "        try:\r\n",
    "            word_df.loc[length, \"10\"] = hist_df.loc[10, \"Probability\"]\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "    except:\r\n",
    "        pass\r\n",
    "      \r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.295181</td>\n",
       "      <td>0.091867</td>\n",
       "      <td>0.090361</td>\n",
       "      <td>0.076807</td>\n",
       "      <td>0.156627</td>\n",
       "      <td>0.149849</td>\n",
       "      <td>0.063253</td>\n",
       "      <td>0.052711</td>\n",
       "      <td>0.023343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5001</td>\n",
       "      <td>0.309023</td>\n",
       "      <td>0.144623</td>\n",
       "      <td>0.087763</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.203956</td>\n",
       "      <td>0.053152</td>\n",
       "      <td>0.048208</td>\n",
       "      <td>0.065513</td>\n",
       "      <td>0.037083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1094</td>\n",
       "      <td>0.251256</td>\n",
       "      <td>0.276382</td>\n",
       "      <td>0.221106</td>\n",
       "      <td>0.251256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5177</td>\n",
       "      <td>0.015320</td>\n",
       "      <td>0.153930</td>\n",
       "      <td>0.133139</td>\n",
       "      <td>0.080978</td>\n",
       "      <td>0.121831</td>\n",
       "      <td>0.095386</td>\n",
       "      <td>0.093380</td>\n",
       "      <td>0.071129</td>\n",
       "      <td>0.163779</td>\n",
       "      <td>0.066569</td>\n",
       "      <td>0.00456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5002</td>\n",
       "      <td>0.086505</td>\n",
       "      <td>0.095156</td>\n",
       "      <td>0.282007</td>\n",
       "      <td>0.140138</td>\n",
       "      <td>0.053633</td>\n",
       "      <td>0.171280</td>\n",
       "      <td>0.171280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Word         0         1         2         3         4         5         6  \\\n",
       "0  5000  0.295181  0.091867  0.090361  0.076807  0.156627  0.149849  0.063253   \n",
       "1  5001  0.309023  0.144623  0.087763  0.050680  0.203956  0.053152  0.048208   \n",
       "2  1094  0.251256  0.276382  0.221106  0.251256  0.000000  0.000000  0.000000   \n",
       "3  5177  0.015320  0.153930  0.133139  0.080978  0.121831  0.095386  0.093380   \n",
       "4  5002  0.086505  0.095156  0.282007  0.140138  0.053633  0.171280  0.171280   \n",
       "\n",
       "          7         8         9       10  \n",
       "0  0.052711  0.023343  0.000000  0.00000  \n",
       "1  0.065513  0.037083  0.000000  0.00000  \n",
       "2  0.000000  0.000000  0.000000  0.00000  \n",
       "3  0.071129  0.163779  0.066569  0.00456  \n",
       "4  0.000000  0.000000  0.000000  0.00000  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df = word_df.fillna(0)\r\n",
    "word_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>Adjectives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>Noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>Noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>Noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004</td>\n",
       "      <td>Noun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id        Type\n",
       "0  2000  Adjectives\n",
       "1  2001        Noun\n",
       "2  2002        Noun\n",
       "3  2003        Noun\n",
       "4  2004        Noun"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading lemmas from postgreSQL\r\n",
    "lemmas_df = pd.read_sql_table('lemmas_labelled', con=engine)\r\n",
    "lemmas_df.drop(columns=\"index\", inplace=True)\r\n",
    "lemmas_df = lemmas_df[[\"id\", \"Type\"]]\r\n",
    "lemmas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>Verb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>Verb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002</td>\n",
       "      <td>Particles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>Conjunctions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004</td>\n",
       "      <td>Verb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id          Type\n",
       "0  1000          Verb\n",
       "1  1001          Verb\n",
       "2  1002     Particles\n",
       "3  1003  Conjunctions\n",
       "4  1004          Verb"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading clitics from postgreSQL\r\n",
    "clitics_df = pd.read_sql_table('clitics_and_postpositions_labelled', con=engine)\r\n",
    "clitics_df.drop(columns=\"index\", inplace=True)\r\n",
    "clitics_df[\"id\"] = clitics_df[\"id\"].str.replace('-','')\r\n",
    "clitics_df = clitics_df[[\"id\", \"Type\"]]\r\n",
    "clitics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5131</td>\n",
       "      <td>Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4020</td>\n",
       "      <td>Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5133</td>\n",
       "      <td>Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4007</td>\n",
       "      <td>Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4008</td>\n",
       "      <td>Syllable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id      Type\n",
       "0  5131  Syllable\n",
       "1  4020  Syllable\n",
       "2  5133  Syllable\n",
       "3  4007  Syllable\n",
       "4  4008  Syllable"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading syllables from postgreSQL\r\n",
    "syllables_df = pd.read_sql_table('syllables', con=engine)\r\n",
    "syllables_df.drop(columns=\"index\", inplace=True)\r\n",
    "syllables_df[\"id\"] = syllables_df[\"id\"].str.replace('-','')\r\n",
    "syllables_df[\"Type\"] = \"Syllable\"\r\n",
    "syllables_df = syllables_df[[\"id\", \"Type\"]]\r\n",
    "syllables_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4035</td>\n",
       "      <td>Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4035</td>\n",
       "      <td>Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4018</td>\n",
       "      <td>Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4036</td>\n",
       "      <td>Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4036</td>\n",
       "      <td>Syllable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id      Type\n",
       "0  4035  Syllable\n",
       "1  4035  Syllable\n",
       "2  4018  Syllable\n",
       "3  4036  Syllable\n",
       "4  4036  Syllable"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading morphemes from postgreSQL\r\n",
    "morphemes_df = pd.read_sql_table('morphemes_labelled', con=engine)\r\n",
    "morphemes_df.drop(columns=\"index\", inplace=True)\r\n",
    "morphemes_df[\"id\"] = morphemes_df[\"id\"].str.replace('-','')\r\n",
    "\r\n",
    "morphemes_df = morphemes_df[[\"id\"]]\r\n",
    "morphemes_df[\"Type\"] = \"Syllable\"\r\n",
    "\r\n",
    "morphemes_df.dropna(inplace=True)\r\n",
    "morphemes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4035</td>\n",
       "      <td>Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4018</td>\n",
       "      <td>Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4036</td>\n",
       "      <td>Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4014</td>\n",
       "      <td>Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4040</td>\n",
       "      <td>Syllable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Word      Type\n",
       "0  4035  Syllable\n",
       "1  4018  Syllable\n",
       "2  4036  Syllable\n",
       "3  4014  Syllable\n",
       "4  4040  Syllable"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenating tables\r\n",
    "labelled_logos =  pd.concat([morphemes_df, syllables_df, clitics_df, lemmas_df])\r\n",
    "labelled_logos.reset_index(drop=True, inplace=True)\r\n",
    "labelled_logos.drop_duplicates(subset=\"id\", inplace=True)\r\n",
    "labelled_logos.reset_index(drop=True, inplace=True)\r\n",
    "labelled_logos.rename(columns = {\"id\": \"Word\"}, inplace=True)\r\n",
    "labelled_logos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Noun            866\n",
       "Verb            302\n",
       "Syllable        231\n",
       "Adjectives      162\n",
       "Numerals        130\n",
       "Adverb          118\n",
       "Conjunctions     60\n",
       "Particles        33\n",
       "Determiners      17\n",
       "Quantifiers      10\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_logos[\"Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>3532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>3533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>3534</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>3535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>3536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Syllable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word    0    1    2    3    4    5    6    7    8    9   10  \\\n",
       "1920  3532  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1921  3533  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1922  3534  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1923  3535  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1924  3536  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "              Type  \n",
       "1920  Not Syllable  \n",
       "1921  Not Syllable  \n",
       "1922  Not Syllable  \n",
       "1923  Not Syllable  \n",
       "1924  Not Syllable  "
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_word = word_df.merge(labelled_logos, on=\"Word\", how=\"left\")\r\n",
    "merged_word = merged_word.fillna(0)\r\n",
    "for i in range(len(merged_word[\"Type\"])):\r\n",
    "    if merged_word.loc[i, \"Type\"] != \"Syllable\":\r\n",
    "        merged_word.loc[i, \"Type\"] = \"Not Syllable\"\r\n",
    "merged_word.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type_Not Syllable</th>\n",
       "      <th>Type_Syllable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type_Not Syllable  Type_Syllable\n",
       "0                0.0            1.0\n",
       "1                0.0            1.0\n",
       "2                1.0            0.0\n",
       "3                0.0            1.0\n",
       "4                0.0            1.0"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\r\n",
    "# Create a OneHotEncoder instance\r\n",
    "enc = OneHotEncoder(sparse=False)\r\n",
    "values = merged_word[\"Type\"].values\r\n",
    "values = values.reshape(-1,1)\r\n",
    "values = values.astype(str)\r\n",
    " \r\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\r\n",
    "encode_df = pd.DataFrame(enc.fit_transform(values))\r\n",
    "\r\n",
    "# Add the encoded variable names to the dataframe\r\n",
    "encode_df.columns = enc.get_feature_names([\"Type\"])\r\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>Type_Syllable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.295181</td>\n",
       "      <td>0.091867</td>\n",
       "      <td>0.090361</td>\n",
       "      <td>0.076807</td>\n",
       "      <td>0.156627</td>\n",
       "      <td>0.149849</td>\n",
       "      <td>0.063253</td>\n",
       "      <td>0.052711</td>\n",
       "      <td>0.023343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5001</td>\n",
       "      <td>0.309023</td>\n",
       "      <td>0.144623</td>\n",
       "      <td>0.087763</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.203956</td>\n",
       "      <td>0.053152</td>\n",
       "      <td>0.048208</td>\n",
       "      <td>0.065513</td>\n",
       "      <td>0.037083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1094</td>\n",
       "      <td>0.251256</td>\n",
       "      <td>0.276382</td>\n",
       "      <td>0.221106</td>\n",
       "      <td>0.251256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5177</td>\n",
       "      <td>0.015320</td>\n",
       "      <td>0.153930</td>\n",
       "      <td>0.133139</td>\n",
       "      <td>0.080978</td>\n",
       "      <td>0.121831</td>\n",
       "      <td>0.095386</td>\n",
       "      <td>0.093380</td>\n",
       "      <td>0.071129</td>\n",
       "      <td>0.163779</td>\n",
       "      <td>0.066569</td>\n",
       "      <td>0.00456</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5002</td>\n",
       "      <td>0.086505</td>\n",
       "      <td>0.095156</td>\n",
       "      <td>0.282007</td>\n",
       "      <td>0.140138</td>\n",
       "      <td>0.053633</td>\n",
       "      <td>0.171280</td>\n",
       "      <td>0.171280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Word         0         1         2         3         4         5         6  \\\n",
       "0  5000  0.295181  0.091867  0.090361  0.076807  0.156627  0.149849  0.063253   \n",
       "1  5001  0.309023  0.144623  0.087763  0.050680  0.203956  0.053152  0.048208   \n",
       "2  1094  0.251256  0.276382  0.221106  0.251256  0.000000  0.000000  0.000000   \n",
       "3  5177  0.015320  0.153930  0.133139  0.080978  0.121831  0.095386  0.093380   \n",
       "4  5002  0.086505  0.095156  0.282007  0.140138  0.053633  0.171280  0.171280   \n",
       "\n",
       "          7         8         9       10  Type_Syllable  \n",
       "0  0.052711  0.023343  0.000000  0.00000            1.0  \n",
       "1  0.065513  0.037083  0.000000  0.00000            1.0  \n",
       "2  0.000000  0.000000  0.000000  0.00000            0.0  \n",
       "3  0.071129  0.163779  0.066569  0.00456            1.0  \n",
       "4  0.000000  0.000000  0.000000  0.00000            1.0  "
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_word = merged_word.merge(encode_df,left_index=True, right_index=True)\r\n",
    "merged_word = merged_word.drop(columns=[\"Type\",\"Type_Not Syllable\"])\r\n",
    "merged_word.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228.0"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_word[\"Type_Syllable\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1925"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_word[\"Type_Syllable\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "X = merged_word.drop(columns=[\"Word\", \"Type_Syllable\"])\r\n",
    "X = np.asarray(X).astype('float32')\r\n",
    "y = merged_word[[\"Type_Syllable\"]]\r\n",
    "y = np.asarray(y).astype('int')\r\n",
    "\r\n",
    "# Split the preprocessed data into a training and testing dataset\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\r\n",
    "scaler = StandardScaler()\r\n",
    "\r\n",
    "# Fit the StandardScaler\r\n",
    "X_scaler = scaler.fit(X_train)\r\n",
    "\r\n",
    "# Scale the data\r\n",
    "X_train_scaled = X_scaler.transform(X_train)\r\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=10)\r\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN\r\n",
    "smote_enn = SMOTEENN(random_state=0)\r\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SVM model\r\n",
    "svm = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\r\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\r\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\r\n",
    "svm.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SVM model accuracy: 0.786\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\r\n",
    "y_pred = svm.predict(X_test_scaled)\r\n",
    "print(f\" SVM model accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[364,  61],\n",
       "       [ 30,  27]], dtype=int64)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\r\n",
    "y_pred = model.predict(X_test)\r\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.92      0.86      0.47      0.89      0.64      0.42       425\n",
      "          1       0.31      0.47      0.86      0.37      0.64      0.39        57\n",
      "\n",
      "avg / total       0.85      0.81      0.52      0.83      0.64      0.42       482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\r\n",
    "# Print the imbalanced classification report\r\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(n_inputs, n_outputs):\r\n",
    "\tmodel = Sequential()\r\n",
    "\tmodel.add(Dense(100, input_dim=n_inputs, kernel_initializer='he_uniform', activation='softmax'))\r\n",
    "\tmodel.add(Dense(100, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\r\n",
    "\tmodel.add(Dense(100, input_dim=n_inputs, kernel_initializer='he_uniform', activation='softmax'))\r\n",
    "\tmodel.add(Dense(n_outputs, activation='sigmoid'))\r\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\r\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "80/80 - 1s - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 2/500\n",
      "80/80 - 0s - loss: 0.6921 - accuracy: 0.5440\n",
      "Epoch 3/500\n",
      "80/80 - 0s - loss: 0.6861 - accuracy: 0.6458\n",
      "Epoch 4/500\n",
      "80/80 - 0s - loss: 0.6691 - accuracy: 0.6612\n",
      "Epoch 5/500\n",
      "80/80 - 0s - loss: 0.6501 - accuracy: 0.6690\n",
      "Epoch 6/500\n",
      "80/80 - 0s - loss: 0.6368 - accuracy: 0.6718\n",
      "Epoch 7/500\n",
      "80/80 - 0s - loss: 0.6285 - accuracy: 0.6757\n",
      "Epoch 8/500\n",
      "80/80 - 0s - loss: 0.6227 - accuracy: 0.6765\n",
      "Epoch 9/500\n",
      "80/80 - 0s - loss: 0.6196 - accuracy: 0.6722\n",
      "Epoch 10/500\n",
      "80/80 - 0s - loss: 0.6170 - accuracy: 0.6761\n",
      "Epoch 11/500\n",
      "80/80 - 0s - loss: 0.6156 - accuracy: 0.6671\n",
      "Epoch 12/500\n",
      "80/80 - 0s - loss: 0.6142 - accuracy: 0.6722\n",
      "Epoch 13/500\n",
      "80/80 - 0s - loss: 0.6147 - accuracy: 0.6694\n",
      "Epoch 14/500\n",
      "80/80 - 0s - loss: 0.6124 - accuracy: 0.6698\n",
      "Epoch 15/500\n",
      "80/80 - 0s - loss: 0.6121 - accuracy: 0.6722\n",
      "Epoch 16/500\n",
      "80/80 - 0s - loss: 0.6104 - accuracy: 0.6690\n",
      "Epoch 17/500\n",
      "80/80 - 0s - loss: 0.6101 - accuracy: 0.6686\n",
      "Epoch 18/500\n",
      "80/80 - 0s - loss: 0.6090 - accuracy: 0.6671\n",
      "Epoch 19/500\n",
      "80/80 - 0s - loss: 0.6081 - accuracy: 0.6678\n",
      "Epoch 20/500\n",
      "80/80 - 0s - loss: 0.6080 - accuracy: 0.6659\n",
      "Epoch 21/500\n",
      "80/80 - 0s - loss: 0.6063 - accuracy: 0.6698\n",
      "Epoch 22/500\n",
      "80/80 - 0s - loss: 0.6066 - accuracy: 0.6737\n",
      "Epoch 23/500\n",
      "80/80 - 0s - loss: 0.6055 - accuracy: 0.6659\n",
      "Epoch 24/500\n",
      "80/80 - 0s - loss: 0.6050 - accuracy: 0.6702\n",
      "Epoch 25/500\n",
      "80/80 - 0s - loss: 0.6038 - accuracy: 0.6722\n",
      "Epoch 26/500\n",
      "80/80 - 0s - loss: 0.6026 - accuracy: 0.6675\n",
      "Epoch 27/500\n",
      "80/80 - 0s - loss: 0.6033 - accuracy: 0.6682\n",
      "Epoch 28/500\n",
      "80/80 - 0s - loss: 0.6021 - accuracy: 0.6737\n",
      "Epoch 29/500\n",
      "80/80 - 0s - loss: 0.6022 - accuracy: 0.6730\n",
      "Epoch 30/500\n",
      "80/80 - 0s - loss: 0.6018 - accuracy: 0.6671\n",
      "Epoch 31/500\n",
      "80/80 - 0s - loss: 0.6025 - accuracy: 0.6722\n",
      "Epoch 32/500\n",
      "80/80 - 0s - loss: 0.6006 - accuracy: 0.6745\n",
      "Epoch 33/500\n",
      "80/80 - 0s - loss: 0.6008 - accuracy: 0.6694\n",
      "Epoch 34/500\n",
      "80/80 - 0s - loss: 0.5997 - accuracy: 0.6694\n",
      "Epoch 35/500\n",
      "80/80 - 0s - loss: 0.6003 - accuracy: 0.6694\n",
      "Epoch 36/500\n",
      "80/80 - 0s - loss: 0.5995 - accuracy: 0.6694\n",
      "Epoch 37/500\n",
      "80/80 - 0s - loss: 0.6000 - accuracy: 0.6714\n",
      "Epoch 38/500\n",
      "80/80 - 0s - loss: 0.5997 - accuracy: 0.6718\n",
      "Epoch 39/500\n",
      "80/80 - 0s - loss: 0.5993 - accuracy: 0.6675\n",
      "Epoch 40/500\n",
      "80/80 - 0s - loss: 0.5988 - accuracy: 0.6706\n",
      "Epoch 41/500\n",
      "80/80 - 0s - loss: 0.5989 - accuracy: 0.6710\n",
      "Epoch 42/500\n",
      "80/80 - 0s - loss: 0.5982 - accuracy: 0.6690\n",
      "Epoch 43/500\n",
      "80/80 - 0s - loss: 0.5982 - accuracy: 0.6690\n",
      "Epoch 44/500\n",
      "80/80 - 0s - loss: 0.5979 - accuracy: 0.6706\n",
      "Epoch 45/500\n",
      "80/80 - 0s - loss: 0.5988 - accuracy: 0.6726\n",
      "Epoch 46/500\n",
      "80/80 - 0s - loss: 0.5971 - accuracy: 0.6741\n",
      "Epoch 47/500\n",
      "80/80 - 0s - loss: 0.5977 - accuracy: 0.6706\n",
      "Epoch 48/500\n",
      "80/80 - 0s - loss: 0.5976 - accuracy: 0.6678\n",
      "Epoch 49/500\n",
      "80/80 - 0s - loss: 0.5966 - accuracy: 0.6737\n",
      "Epoch 50/500\n",
      "80/80 - 0s - loss: 0.5973 - accuracy: 0.6671\n",
      "Epoch 51/500\n",
      "80/80 - 0s - loss: 0.5971 - accuracy: 0.6690\n",
      "Epoch 52/500\n",
      "80/80 - 0s - loss: 0.5968 - accuracy: 0.6678\n",
      "Epoch 53/500\n",
      "80/80 - 0s - loss: 0.5969 - accuracy: 0.6714\n",
      "Epoch 54/500\n",
      "80/80 - 0s - loss: 0.5962 - accuracy: 0.6698\n",
      "Epoch 55/500\n",
      "80/80 - 0s - loss: 0.5964 - accuracy: 0.6663\n",
      "Epoch 56/500\n",
      "80/80 - 0s - loss: 0.5969 - accuracy: 0.6655\n",
      "Epoch 57/500\n",
      "80/80 - 0s - loss: 0.5963 - accuracy: 0.6706\n",
      "Epoch 58/500\n",
      "80/80 - 0s - loss: 0.5961 - accuracy: 0.6663\n",
      "Epoch 59/500\n",
      "80/80 - 0s - loss: 0.5959 - accuracy: 0.6722\n",
      "Epoch 60/500\n",
      "80/80 - 0s - loss: 0.5961 - accuracy: 0.6690\n",
      "Epoch 61/500\n",
      "80/80 - 0s - loss: 0.5955 - accuracy: 0.6694\n",
      "Epoch 62/500\n",
      "80/80 - 0s - loss: 0.5958 - accuracy: 0.6726\n",
      "Epoch 63/500\n",
      "80/80 - 0s - loss: 0.5961 - accuracy: 0.6667\n",
      "Epoch 64/500\n",
      "80/80 - 0s - loss: 0.5956 - accuracy: 0.6682\n",
      "Epoch 65/500\n",
      "80/80 - 0s - loss: 0.5960 - accuracy: 0.6698\n",
      "Epoch 66/500\n",
      "80/80 - 0s - loss: 0.5957 - accuracy: 0.6710\n",
      "Epoch 67/500\n",
      "80/80 - 0s - loss: 0.5959 - accuracy: 0.6718\n",
      "Epoch 68/500\n",
      "80/80 - 0s - loss: 0.5968 - accuracy: 0.6757\n",
      "Epoch 69/500\n",
      "80/80 - 0s - loss: 0.5954 - accuracy: 0.6702\n",
      "Epoch 70/500\n",
      "80/80 - 0s - loss: 0.5952 - accuracy: 0.6671\n",
      "Epoch 71/500\n",
      "80/80 - 0s - loss: 0.5952 - accuracy: 0.6718\n",
      "Epoch 72/500\n",
      "80/80 - 0s - loss: 0.5957 - accuracy: 0.6678\n",
      "Epoch 73/500\n",
      "80/80 - 0s - loss: 0.5954 - accuracy: 0.6698\n",
      "Epoch 74/500\n",
      "80/80 - 0s - loss: 0.5956 - accuracy: 0.6635\n",
      "Epoch 75/500\n",
      "80/80 - 0s - loss: 0.5949 - accuracy: 0.6655\n",
      "Epoch 76/500\n",
      "80/80 - 0s - loss: 0.5954 - accuracy: 0.6706\n",
      "Epoch 77/500\n",
      "80/80 - 0s - loss: 0.5950 - accuracy: 0.6730\n",
      "Epoch 78/500\n",
      "80/80 - 0s - loss: 0.5955 - accuracy: 0.6722\n",
      "Epoch 79/500\n",
      "80/80 - 0s - loss: 0.5953 - accuracy: 0.6730\n",
      "Epoch 80/500\n",
      "80/80 - 0s - loss: 0.5950 - accuracy: 0.6757\n",
      "Epoch 81/500\n",
      "80/80 - 0s - loss: 0.5953 - accuracy: 0.6667\n",
      "Epoch 82/500\n",
      "80/80 - 0s - loss: 0.5954 - accuracy: 0.6710\n",
      "Epoch 83/500\n",
      "80/80 - 0s - loss: 0.5941 - accuracy: 0.6800\n",
      "Epoch 84/500\n",
      "80/80 - 0s - loss: 0.5955 - accuracy: 0.6710\n",
      "Epoch 85/500\n",
      "80/80 - 0s - loss: 0.5942 - accuracy: 0.6686\n",
      "Epoch 86/500\n",
      "80/80 - 0s - loss: 0.5951 - accuracy: 0.6682\n",
      "Epoch 87/500\n",
      "80/80 - 0s - loss: 0.5948 - accuracy: 0.6675\n",
      "Epoch 88/500\n",
      "80/80 - 0s - loss: 0.5956 - accuracy: 0.6730\n",
      "Epoch 89/500\n",
      "80/80 - 0s - loss: 0.5955 - accuracy: 0.6663\n",
      "Epoch 90/500\n",
      "80/80 - 0s - loss: 0.5946 - accuracy: 0.6682\n",
      "Epoch 91/500\n",
      "80/80 - 0s - loss: 0.5941 - accuracy: 0.6675\n",
      "Epoch 92/500\n",
      "80/80 - 0s - loss: 0.5944 - accuracy: 0.6686\n",
      "Epoch 93/500\n",
      "80/80 - 0s - loss: 0.5947 - accuracy: 0.6777\n",
      "Epoch 94/500\n",
      "80/80 - 0s - loss: 0.5942 - accuracy: 0.6663\n",
      "Epoch 95/500\n",
      "80/80 - 0s - loss: 0.5940 - accuracy: 0.6678\n",
      "Epoch 96/500\n",
      "80/80 - 0s - loss: 0.5946 - accuracy: 0.6745\n",
      "Epoch 97/500\n",
      "80/80 - 0s - loss: 0.5939 - accuracy: 0.6682\n",
      "Epoch 98/500\n",
      "80/80 - 0s - loss: 0.5936 - accuracy: 0.6678\n",
      "Epoch 99/500\n",
      "80/80 - 0s - loss: 0.5935 - accuracy: 0.6777\n",
      "Epoch 100/500\n",
      "80/80 - 0s - loss: 0.5939 - accuracy: 0.6659\n",
      "Epoch 101/500\n",
      "80/80 - 0s - loss: 0.5938 - accuracy: 0.6651\n",
      "Epoch 102/500\n",
      "80/80 - 0s - loss: 0.5939 - accuracy: 0.6726\n",
      "Epoch 103/500\n",
      "80/80 - 0s - loss: 0.5936 - accuracy: 0.6647\n",
      "Epoch 104/500\n",
      "80/80 - 0s - loss: 0.5943 - accuracy: 0.6694\n",
      "Epoch 105/500\n",
      "80/80 - 0s - loss: 0.5935 - accuracy: 0.6737\n",
      "Epoch 106/500\n",
      "80/80 - 0s - loss: 0.5942 - accuracy: 0.6745\n",
      "Epoch 107/500\n",
      "80/80 - 0s - loss: 0.5929 - accuracy: 0.6682\n",
      "Epoch 108/500\n",
      "80/80 - 0s - loss: 0.5933 - accuracy: 0.6741\n",
      "Epoch 109/500\n",
      "80/80 - 0s - loss: 0.5928 - accuracy: 0.6741\n",
      "Epoch 110/500\n",
      "80/80 - 0s - loss: 0.5934 - accuracy: 0.6706\n",
      "Epoch 111/500\n",
      "80/80 - 0s - loss: 0.5937 - accuracy: 0.6718\n",
      "Epoch 112/500\n",
      "80/80 - 0s - loss: 0.5933 - accuracy: 0.6682\n",
      "Epoch 113/500\n",
      "80/80 - 0s - loss: 0.5939 - accuracy: 0.6737\n",
      "Epoch 114/500\n",
      "80/80 - 0s - loss: 0.5929 - accuracy: 0.6698\n",
      "Epoch 115/500\n",
      "80/80 - 0s - loss: 0.5938 - accuracy: 0.6706\n",
      "Epoch 116/500\n",
      "80/80 - 0s - loss: 0.5936 - accuracy: 0.6675\n",
      "Epoch 117/500\n",
      "80/80 - 0s - loss: 0.5936 - accuracy: 0.6733\n",
      "Epoch 118/500\n",
      "80/80 - 0s - loss: 0.5934 - accuracy: 0.6718\n",
      "Epoch 119/500\n",
      "80/80 - 0s - loss: 0.5927 - accuracy: 0.6667\n",
      "Epoch 120/500\n",
      "80/80 - 0s - loss: 0.5929 - accuracy: 0.6698\n",
      "Epoch 121/500\n",
      "80/80 - 0s - loss: 0.5933 - accuracy: 0.6722\n",
      "Epoch 122/500\n",
      "80/80 - 0s - loss: 0.5923 - accuracy: 0.6722\n",
      "Epoch 123/500\n",
      "80/80 - 0s - loss: 0.5925 - accuracy: 0.6765\n",
      "Epoch 124/500\n",
      "80/80 - 0s - loss: 0.5923 - accuracy: 0.6698\n",
      "Epoch 125/500\n",
      "80/80 - 0s - loss: 0.5926 - accuracy: 0.6710\n",
      "Epoch 126/500\n",
      "80/80 - 0s - loss: 0.5924 - accuracy: 0.6686\n",
      "Epoch 127/500\n",
      "80/80 - 0s - loss: 0.5919 - accuracy: 0.6686\n",
      "Epoch 128/500\n",
      "80/80 - 0s - loss: 0.5926 - accuracy: 0.6733\n",
      "Epoch 129/500\n",
      "80/80 - 0s - loss: 0.5924 - accuracy: 0.6726\n",
      "Epoch 130/500\n",
      "80/80 - 0s - loss: 0.5922 - accuracy: 0.6663\n",
      "Epoch 131/500\n",
      "80/80 - 0s - loss: 0.5926 - accuracy: 0.6773\n",
      "Epoch 132/500\n",
      "80/80 - 0s - loss: 0.5932 - accuracy: 0.6722\n",
      "Epoch 133/500\n",
      "80/80 - 0s - loss: 0.5924 - accuracy: 0.6639\n",
      "Epoch 134/500\n",
      "80/80 - 0s - loss: 0.5919 - accuracy: 0.6733\n",
      "Epoch 135/500\n",
      "80/80 - 0s - loss: 0.5927 - accuracy: 0.6726\n",
      "Epoch 136/500\n",
      "80/80 - 0s - loss: 0.5919 - accuracy: 0.6675\n",
      "Epoch 137/500\n",
      "80/80 - 0s - loss: 0.5916 - accuracy: 0.6757\n",
      "Epoch 138/500\n",
      "80/80 - 0s - loss: 0.5913 - accuracy: 0.6749\n",
      "Epoch 139/500\n",
      "80/80 - 0s - loss: 0.5919 - accuracy: 0.6682\n",
      "Epoch 140/500\n",
      "80/80 - 0s - loss: 0.5920 - accuracy: 0.6675\n",
      "Epoch 141/500\n",
      "80/80 - 0s - loss: 0.5928 - accuracy: 0.6714\n",
      "Epoch 142/500\n",
      "80/80 - 0s - loss: 0.5921 - accuracy: 0.6675\n",
      "Epoch 143/500\n",
      "80/80 - 0s - loss: 0.5916 - accuracy: 0.6726\n",
      "Epoch 144/500\n",
      "80/80 - 0s - loss: 0.5923 - accuracy: 0.6686\n",
      "Epoch 145/500\n",
      "80/80 - 0s - loss: 0.5926 - accuracy: 0.6730\n",
      "Epoch 146/500\n",
      "80/80 - 0s - loss: 0.5920 - accuracy: 0.6686\n",
      "Epoch 147/500\n",
      "80/80 - 0s - loss: 0.5928 - accuracy: 0.6773\n",
      "Epoch 148/500\n",
      "80/80 - 0s - loss: 0.5916 - accuracy: 0.6671\n",
      "Epoch 149/500\n",
      "80/80 - 0s - loss: 0.5930 - accuracy: 0.6733\n",
      "Epoch 150/500\n",
      "80/80 - 0s - loss: 0.5911 - accuracy: 0.6722\n",
      "Epoch 151/500\n",
      "80/80 - 0s - loss: 0.5927 - accuracy: 0.6710\n",
      "Epoch 152/500\n",
      "80/80 - 0s - loss: 0.5916 - accuracy: 0.6686\n",
      "Epoch 153/500\n",
      "80/80 - 0s - loss: 0.5898 - accuracy: 0.6777\n",
      "Epoch 154/500\n",
      "80/80 - 0s - loss: 0.5931 - accuracy: 0.6737\n",
      "Epoch 155/500\n",
      "80/80 - 0s - loss: 0.5914 - accuracy: 0.6753\n",
      "Epoch 156/500\n",
      "80/80 - 0s - loss: 0.5912 - accuracy: 0.6714\n",
      "Epoch 157/500\n",
      "80/80 - 0s - loss: 0.5916 - accuracy: 0.6671\n",
      "Epoch 158/500\n",
      "80/80 - 0s - loss: 0.5919 - accuracy: 0.6741\n",
      "Epoch 159/500\n",
      "80/80 - 0s - loss: 0.5913 - accuracy: 0.6690\n",
      "Epoch 160/500\n",
      "80/80 - 0s - loss: 0.5914 - accuracy: 0.6678\n",
      "Epoch 161/500\n",
      "80/80 - 0s - loss: 0.5908 - accuracy: 0.6718\n",
      "Epoch 162/500\n",
      "80/80 - 0s - loss: 0.5908 - accuracy: 0.6698\n",
      "Epoch 163/500\n",
      "80/80 - 0s - loss: 0.5912 - accuracy: 0.6694\n",
      "Epoch 164/500\n",
      "80/80 - 0s - loss: 0.5911 - accuracy: 0.6745\n",
      "Epoch 165/500\n",
      "80/80 - 0s - loss: 0.5910 - accuracy: 0.6682\n",
      "Epoch 166/500\n",
      "80/80 - 0s - loss: 0.5923 - accuracy: 0.6710\n",
      "Epoch 167/500\n",
      "80/80 - 0s - loss: 0.5916 - accuracy: 0.6714\n",
      "Epoch 168/500\n",
      "80/80 - 0s - loss: 0.5905 - accuracy: 0.6694\n",
      "Epoch 169/500\n",
      "80/80 - 0s - loss: 0.5908 - accuracy: 0.6781\n",
      "Epoch 170/500\n",
      "80/80 - 0s - loss: 0.5907 - accuracy: 0.6730\n",
      "Epoch 171/500\n",
      "80/80 - 0s - loss: 0.5905 - accuracy: 0.6765\n",
      "Epoch 172/500\n",
      "80/80 - 0s - loss: 0.5910 - accuracy: 0.6757\n",
      "Epoch 173/500\n",
      "80/80 - 0s - loss: 0.5893 - accuracy: 0.6800\n",
      "Epoch 174/500\n",
      "80/80 - 0s - loss: 0.5912 - accuracy: 0.6710\n",
      "Epoch 175/500\n",
      "80/80 - 0s - loss: 0.5906 - accuracy: 0.6745\n",
      "Epoch 176/500\n",
      "80/80 - 0s - loss: 0.5916 - accuracy: 0.6694\n",
      "Epoch 177/500\n",
      "80/80 - 0s - loss: 0.5903 - accuracy: 0.6741\n",
      "Epoch 178/500\n",
      "80/80 - 0s - loss: 0.5903 - accuracy: 0.6757\n",
      "Epoch 179/500\n",
      "80/80 - 0s - loss: 0.5916 - accuracy: 0.6710\n",
      "Epoch 180/500\n",
      "80/80 - 0s - loss: 0.5913 - accuracy: 0.6733\n",
      "Epoch 181/500\n",
      "80/80 - 0s - loss: 0.5898 - accuracy: 0.6737\n",
      "Epoch 182/500\n",
      "80/80 - 0s - loss: 0.5909 - accuracy: 0.6702\n",
      "Epoch 183/500\n",
      "80/80 - 0s - loss: 0.5907 - accuracy: 0.6737\n",
      "Epoch 184/500\n",
      "80/80 - 0s - loss: 0.5896 - accuracy: 0.6710\n",
      "Epoch 185/500\n",
      "80/80 - 0s - loss: 0.5892 - accuracy: 0.6733\n",
      "Epoch 186/500\n",
      "80/80 - 0s - loss: 0.5907 - accuracy: 0.6698\n",
      "Epoch 187/500\n",
      "80/80 - 0s - loss: 0.5902 - accuracy: 0.6722\n",
      "Epoch 188/500\n",
      "80/80 - 0s - loss: 0.5906 - accuracy: 0.6718\n",
      "Epoch 189/500\n",
      "80/80 - 0s - loss: 0.5895 - accuracy: 0.6741\n",
      "Epoch 190/500\n",
      "80/80 - 0s - loss: 0.5899 - accuracy: 0.6706\n",
      "Epoch 191/500\n",
      "80/80 - 0s - loss: 0.5908 - accuracy: 0.6718\n",
      "Epoch 192/500\n",
      "80/80 - 0s - loss: 0.5898 - accuracy: 0.6686\n",
      "Epoch 193/500\n",
      "80/80 - 0s - loss: 0.5890 - accuracy: 0.6694\n",
      "Epoch 194/500\n",
      "80/80 - 0s - loss: 0.5904 - accuracy: 0.6726\n",
      "Epoch 195/500\n",
      "80/80 - 0s - loss: 0.5912 - accuracy: 0.6686\n",
      "Epoch 196/500\n",
      "80/80 - 0s - loss: 0.5894 - accuracy: 0.6737\n",
      "Epoch 197/500\n",
      "80/80 - 0s - loss: 0.5896 - accuracy: 0.6733\n",
      "Epoch 198/500\n",
      "80/80 - 0s - loss: 0.5875 - accuracy: 0.6769\n",
      "Epoch 199/500\n",
      "80/80 - 0s - loss: 0.5899 - accuracy: 0.6765\n",
      "Epoch 200/500\n",
      "80/80 - 0s - loss: 0.5897 - accuracy: 0.6714\n",
      "Epoch 201/500\n",
      "80/80 - 0s - loss: 0.5901 - accuracy: 0.6745\n",
      "Epoch 202/500\n",
      "80/80 - 0s - loss: 0.5890 - accuracy: 0.6710\n",
      "Epoch 203/500\n",
      "80/80 - 0s - loss: 0.5902 - accuracy: 0.6757\n",
      "Epoch 204/500\n",
      "80/80 - 0s - loss: 0.5889 - accuracy: 0.6757\n",
      "Epoch 205/500\n",
      "80/80 - 0s - loss: 0.5897 - accuracy: 0.6741\n",
      "Epoch 206/500\n",
      "80/80 - 0s - loss: 0.5885 - accuracy: 0.6733\n",
      "Epoch 207/500\n",
      "80/80 - 0s - loss: 0.5885 - accuracy: 0.6733\n",
      "Epoch 208/500\n",
      "80/80 - 0s - loss: 0.5897 - accuracy: 0.6741\n",
      "Epoch 209/500\n",
      "80/80 - 0s - loss: 0.5884 - accuracy: 0.6730\n",
      "Epoch 210/500\n",
      "80/80 - 0s - loss: 0.5881 - accuracy: 0.6781\n",
      "Epoch 211/500\n",
      "80/80 - 0s - loss: 0.5901 - accuracy: 0.6761\n",
      "Epoch 212/500\n",
      "80/80 - 0s - loss: 0.5893 - accuracy: 0.6733\n",
      "Epoch 213/500\n",
      "80/80 - 0s - loss: 0.5882 - accuracy: 0.6698\n",
      "Epoch 214/500\n",
      "80/80 - 0s - loss: 0.5878 - accuracy: 0.6726\n",
      "Epoch 215/500\n",
      "80/80 - 0s - loss: 0.5890 - accuracy: 0.6796\n",
      "Epoch 216/500\n",
      "80/80 - 0s - loss: 0.5899 - accuracy: 0.6733\n",
      "Epoch 217/500\n",
      "80/80 - 0s - loss: 0.5877 - accuracy: 0.6785\n",
      "Epoch 218/500\n",
      "80/80 - 0s - loss: 0.5897 - accuracy: 0.6714\n",
      "Epoch 219/500\n",
      "80/80 - 0s - loss: 0.5885 - accuracy: 0.6753\n",
      "Epoch 220/500\n",
      "80/80 - 0s - loss: 0.5887 - accuracy: 0.6722\n",
      "Epoch 221/500\n",
      "80/80 - 0s - loss: 0.5885 - accuracy: 0.6722\n",
      "Epoch 222/500\n",
      "80/80 - 0s - loss: 0.5884 - accuracy: 0.6749\n",
      "Epoch 223/500\n",
      "80/80 - 0s - loss: 0.5883 - accuracy: 0.6726\n",
      "Epoch 224/500\n",
      "80/80 - 0s - loss: 0.5880 - accuracy: 0.6737\n",
      "Epoch 225/500\n",
      "80/80 - 0s - loss: 0.5880 - accuracy: 0.6749\n",
      "Epoch 226/500\n",
      "80/80 - 0s - loss: 0.5898 - accuracy: 0.6749\n",
      "Epoch 227/500\n",
      "80/80 - 0s - loss: 0.5889 - accuracy: 0.6773\n",
      "Epoch 228/500\n",
      "80/80 - 0s - loss: 0.5884 - accuracy: 0.6773\n",
      "Epoch 229/500\n",
      "80/80 - 0s - loss: 0.5879 - accuracy: 0.6753\n",
      "Epoch 230/500\n",
      "80/80 - 0s - loss: 0.5884 - accuracy: 0.6745\n",
      "Epoch 231/500\n",
      "80/80 - 0s - loss: 0.5899 - accuracy: 0.6757\n",
      "Epoch 232/500\n",
      "80/80 - 0s - loss: 0.5884 - accuracy: 0.6733\n",
      "Epoch 233/500\n",
      "80/80 - 0s - loss: 0.5883 - accuracy: 0.6741\n",
      "Epoch 234/500\n",
      "80/80 - 0s - loss: 0.5879 - accuracy: 0.6730\n",
      "Epoch 235/500\n",
      "80/80 - 0s - loss: 0.5876 - accuracy: 0.6757\n",
      "Epoch 236/500\n",
      "80/80 - 0s - loss: 0.5874 - accuracy: 0.6757\n",
      "Epoch 237/500\n",
      "80/80 - 0s - loss: 0.5874 - accuracy: 0.6777\n",
      "Epoch 238/500\n",
      "80/80 - 0s - loss: 0.5876 - accuracy: 0.6726\n",
      "Epoch 239/500\n",
      "80/80 - 0s - loss: 0.5874 - accuracy: 0.6761\n",
      "Epoch 240/500\n",
      "80/80 - 0s - loss: 0.5876 - accuracy: 0.6757\n",
      "Epoch 241/500\n",
      "80/80 - 0s - loss: 0.5873 - accuracy: 0.6733\n",
      "Epoch 242/500\n",
      "80/80 - 0s - loss: 0.5874 - accuracy: 0.6737\n",
      "Epoch 243/500\n",
      "80/80 - 0s - loss: 0.5883 - accuracy: 0.6722\n",
      "Epoch 244/500\n",
      "80/80 - 0s - loss: 0.5863 - accuracy: 0.6765\n",
      "Epoch 245/500\n",
      "80/80 - 0s - loss: 0.5883 - accuracy: 0.6769\n",
      "Epoch 246/500\n",
      "80/80 - 0s - loss: 0.5866 - accuracy: 0.6769\n",
      "Epoch 247/500\n",
      "80/80 - 0s - loss: 0.5875 - accuracy: 0.6789\n",
      "Epoch 248/500\n",
      "80/80 - 0s - loss: 0.5877 - accuracy: 0.6749\n",
      "Epoch 249/500\n",
      "80/80 - 0s - loss: 0.5868 - accuracy: 0.6765\n",
      "Epoch 250/500\n",
      "80/80 - 0s - loss: 0.5866 - accuracy: 0.6820\n",
      "Epoch 251/500\n",
      "80/80 - 0s - loss: 0.5867 - accuracy: 0.6753\n",
      "Epoch 252/500\n",
      "80/80 - 0s - loss: 0.5883 - accuracy: 0.6792\n",
      "Epoch 253/500\n",
      "80/80 - 0s - loss: 0.5860 - accuracy: 0.6796\n",
      "Epoch 254/500\n",
      "80/80 - 0s - loss: 0.5880 - accuracy: 0.6745\n",
      "Epoch 255/500\n",
      "80/80 - 0s - loss: 0.5866 - accuracy: 0.6749\n",
      "Epoch 256/500\n",
      "80/80 - 0s - loss: 0.5872 - accuracy: 0.6757\n",
      "Epoch 257/500\n",
      "80/80 - 0s - loss: 0.5866 - accuracy: 0.6792\n",
      "Epoch 258/500\n",
      "80/80 - 0s - loss: 0.5869 - accuracy: 0.6753\n",
      "Epoch 259/500\n",
      "80/80 - 0s - loss: 0.5858 - accuracy: 0.6777\n",
      "Epoch 260/500\n",
      "80/80 - 0s - loss: 0.5859 - accuracy: 0.6808\n",
      "Epoch 261/500\n",
      "80/80 - 0s - loss: 0.5862 - accuracy: 0.6773\n",
      "Epoch 262/500\n",
      "80/80 - 0s - loss: 0.5863 - accuracy: 0.6765\n",
      "Epoch 263/500\n",
      "80/80 - 0s - loss: 0.5872 - accuracy: 0.6757\n",
      "Epoch 264/500\n",
      "80/80 - 0s - loss: 0.5857 - accuracy: 0.6765\n",
      "Epoch 265/500\n",
      "80/80 - 0s - loss: 0.5857 - accuracy: 0.6777\n",
      "Epoch 266/500\n",
      "80/80 - 0s - loss: 0.5866 - accuracy: 0.6789\n",
      "Epoch 267/500\n",
      "80/80 - 0s - loss: 0.5858 - accuracy: 0.6789\n",
      "Epoch 268/500\n",
      "80/80 - 0s - loss: 0.5857 - accuracy: 0.6769\n",
      "Epoch 269/500\n",
      "80/80 - 0s - loss: 0.5867 - accuracy: 0.6781\n",
      "Epoch 270/500\n",
      "80/80 - 0s - loss: 0.5853 - accuracy: 0.6765\n",
      "Epoch 271/500\n",
      "80/80 - 0s - loss: 0.5867 - accuracy: 0.6773\n",
      "Epoch 272/500\n",
      "80/80 - 0s - loss: 0.5852 - accuracy: 0.6757\n",
      "Epoch 273/500\n",
      "80/80 - 0s - loss: 0.5877 - accuracy: 0.6730\n",
      "Epoch 274/500\n",
      "80/80 - 0s - loss: 0.5873 - accuracy: 0.6777\n",
      "Epoch 275/500\n",
      "80/80 - 0s - loss: 0.5860 - accuracy: 0.6753\n",
      "Epoch 276/500\n",
      "80/80 - 0s - loss: 0.5845 - accuracy: 0.6757\n",
      "Epoch 277/500\n",
      "80/80 - 0s - loss: 0.5862 - accuracy: 0.6800\n",
      "Epoch 278/500\n",
      "80/80 - 0s - loss: 0.5856 - accuracy: 0.6765\n",
      "Epoch 279/500\n",
      "80/80 - 0s - loss: 0.5863 - accuracy: 0.6792\n",
      "Epoch 280/500\n",
      "80/80 - 0s - loss: 0.5865 - accuracy: 0.6733\n",
      "Epoch 281/500\n",
      "80/80 - 0s - loss: 0.5861 - accuracy: 0.6781\n",
      "Epoch 282/500\n",
      "80/80 - 0s - loss: 0.5864 - accuracy: 0.6820\n",
      "Epoch 283/500\n",
      "80/80 - 0s - loss: 0.5851 - accuracy: 0.6753\n",
      "Epoch 284/500\n",
      "80/80 - 0s - loss: 0.5855 - accuracy: 0.6753\n",
      "Epoch 285/500\n",
      "80/80 - 0s - loss: 0.5846 - accuracy: 0.6773\n",
      "Epoch 286/500\n",
      "80/80 - 0s - loss: 0.5849 - accuracy: 0.6781\n",
      "Epoch 287/500\n",
      "80/80 - 0s - loss: 0.5844 - accuracy: 0.6753\n",
      "Epoch 288/500\n",
      "80/80 - 0s - loss: 0.5850 - accuracy: 0.6828\n",
      "Epoch 289/500\n",
      "80/80 - 0s - loss: 0.5857 - accuracy: 0.6757\n",
      "Epoch 290/500\n",
      "80/80 - 0s - loss: 0.5867 - accuracy: 0.6785\n",
      "Epoch 291/500\n",
      "80/80 - 0s - loss: 0.5854 - accuracy: 0.6785\n",
      "Epoch 292/500\n",
      "80/80 - 0s - loss: 0.5851 - accuracy: 0.6749\n",
      "Epoch 293/500\n",
      "80/80 - 0s - loss: 0.5848 - accuracy: 0.6722\n",
      "Epoch 294/500\n",
      "80/80 - 0s - loss: 0.5844 - accuracy: 0.6777\n",
      "Epoch 295/500\n",
      "80/80 - 0s - loss: 0.5846 - accuracy: 0.6761\n",
      "Epoch 296/500\n",
      "80/80 - 0s - loss: 0.5859 - accuracy: 0.6777\n",
      "Epoch 297/500\n",
      "80/80 - 0s - loss: 0.5837 - accuracy: 0.6816\n",
      "Epoch 298/500\n",
      "80/80 - 0s - loss: 0.5840 - accuracy: 0.6812\n",
      "Epoch 299/500\n",
      "80/80 - 0s - loss: 0.5832 - accuracy: 0.6828\n",
      "Epoch 300/500\n",
      "80/80 - 0s - loss: 0.5840 - accuracy: 0.6773\n",
      "Epoch 301/500\n",
      "80/80 - 0s - loss: 0.5842 - accuracy: 0.6812\n",
      "Epoch 302/500\n",
      "80/80 - 0s - loss: 0.5843 - accuracy: 0.6781\n",
      "Epoch 303/500\n",
      "80/80 - 0s - loss: 0.5833 - accuracy: 0.6792\n",
      "Epoch 304/500\n",
      "80/80 - 0s - loss: 0.5847 - accuracy: 0.6761\n",
      "Epoch 305/500\n",
      "80/80 - 0s - loss: 0.5845 - accuracy: 0.6781\n",
      "Epoch 306/500\n",
      "80/80 - 0s - loss: 0.5840 - accuracy: 0.6733\n",
      "Epoch 307/500\n",
      "80/80 - 0s - loss: 0.5834 - accuracy: 0.6836\n",
      "Epoch 308/500\n",
      "80/80 - 0s - loss: 0.5854 - accuracy: 0.6749\n",
      "Epoch 309/500\n",
      "80/80 - 0s - loss: 0.5843 - accuracy: 0.6745\n",
      "Epoch 310/500\n",
      "80/80 - 0s - loss: 0.5843 - accuracy: 0.6816\n",
      "Epoch 311/500\n",
      "80/80 - 0s - loss: 0.5839 - accuracy: 0.6781\n",
      "Epoch 312/500\n",
      "80/80 - 0s - loss: 0.5840 - accuracy: 0.6781\n",
      "Epoch 313/500\n",
      "80/80 - 0s - loss: 0.5840 - accuracy: 0.6812\n",
      "Epoch 314/500\n",
      "80/80 - 0s - loss: 0.5849 - accuracy: 0.6785\n",
      "Epoch 315/500\n",
      "80/80 - 0s - loss: 0.5840 - accuracy: 0.6832\n",
      "Epoch 316/500\n",
      "80/80 - 0s - loss: 0.5827 - accuracy: 0.6804\n",
      "Epoch 317/500\n",
      "80/80 - 0s - loss: 0.5840 - accuracy: 0.6832\n",
      "Epoch 318/500\n",
      "80/80 - 0s - loss: 0.5845 - accuracy: 0.6820\n",
      "Epoch 319/500\n",
      "80/80 - 0s - loss: 0.5854 - accuracy: 0.6789\n",
      "Epoch 320/500\n",
      "80/80 - 0s - loss: 0.5839 - accuracy: 0.6785\n",
      "Epoch 321/500\n",
      "80/80 - 0s - loss: 0.5840 - accuracy: 0.6836\n",
      "Epoch 322/500\n",
      "80/80 - 0s - loss: 0.5845 - accuracy: 0.6847\n",
      "Epoch 323/500\n",
      "80/80 - 0s - loss: 0.5831 - accuracy: 0.6863\n",
      "Epoch 324/500\n",
      "80/80 - 0s - loss: 0.5832 - accuracy: 0.6777\n",
      "Epoch 325/500\n",
      "80/80 - 0s - loss: 0.5813 - accuracy: 0.6847\n",
      "Epoch 326/500\n",
      "80/80 - 0s - loss: 0.5853 - accuracy: 0.6789\n",
      "Epoch 327/500\n",
      "80/80 - 0s - loss: 0.5830 - accuracy: 0.6847\n",
      "Epoch 328/500\n",
      "80/80 - 0s - loss: 0.5840 - accuracy: 0.6808\n",
      "Epoch 329/500\n",
      "80/80 - 0s - loss: 0.5841 - accuracy: 0.6769\n",
      "Epoch 330/500\n",
      "80/80 - 0s - loss: 0.5836 - accuracy: 0.6785\n",
      "Epoch 331/500\n",
      "80/80 - 0s - loss: 0.5845 - accuracy: 0.6773\n",
      "Epoch 332/500\n",
      "80/80 - 0s - loss: 0.5838 - accuracy: 0.6765\n",
      "Epoch 333/500\n",
      "80/80 - 0s - loss: 0.5833 - accuracy: 0.6773\n",
      "Epoch 334/500\n",
      "80/80 - 0s - loss: 0.5836 - accuracy: 0.6777\n",
      "Epoch 335/500\n",
      "80/80 - 0s - loss: 0.5833 - accuracy: 0.6824\n",
      "Epoch 336/500\n",
      "80/80 - 0s - loss: 0.5846 - accuracy: 0.6844\n",
      "Epoch 337/500\n",
      "80/80 - 0s - loss: 0.5819 - accuracy: 0.6812\n",
      "Epoch 338/500\n",
      "80/80 - 0s - loss: 0.5826 - accuracy: 0.6808\n",
      "Epoch 339/500\n",
      "80/80 - 0s - loss: 0.5827 - accuracy: 0.6781\n",
      "Epoch 340/500\n",
      "80/80 - 0s - loss: 0.5837 - accuracy: 0.6800\n",
      "Epoch 341/500\n",
      "80/80 - 0s - loss: 0.5824 - accuracy: 0.6769\n",
      "Epoch 342/500\n",
      "80/80 - 0s - loss: 0.5824 - accuracy: 0.6804\n",
      "Epoch 343/500\n",
      "80/80 - 0s - loss: 0.5826 - accuracy: 0.6777\n",
      "Epoch 344/500\n",
      "80/80 - 0s - loss: 0.5835 - accuracy: 0.6796\n",
      "Epoch 345/500\n",
      "80/80 - 0s - loss: 0.5824 - accuracy: 0.6804\n",
      "Epoch 346/500\n",
      "80/80 - 0s - loss: 0.5822 - accuracy: 0.6804\n",
      "Epoch 347/500\n",
      "80/80 - 0s - loss: 0.5823 - accuracy: 0.6847\n",
      "Epoch 348/500\n",
      "80/80 - 0s - loss: 0.5830 - accuracy: 0.6757\n",
      "Epoch 349/500\n",
      "80/80 - 0s - loss: 0.5824 - accuracy: 0.6804\n",
      "Epoch 350/500\n",
      "80/80 - 0s - loss: 0.5817 - accuracy: 0.6741\n",
      "Epoch 351/500\n",
      "80/80 - 0s - loss: 0.5822 - accuracy: 0.6855\n",
      "Epoch 352/500\n",
      "80/80 - 0s - loss: 0.5824 - accuracy: 0.6812\n",
      "Epoch 353/500\n",
      "80/80 - 0s - loss: 0.5829 - accuracy: 0.6879\n",
      "Epoch 354/500\n",
      "80/80 - 0s - loss: 0.5842 - accuracy: 0.6785\n",
      "Epoch 355/500\n",
      "80/80 - 0s - loss: 0.5833 - accuracy: 0.6757\n",
      "Epoch 356/500\n",
      "80/80 - 0s - loss: 0.5826 - accuracy: 0.6808\n",
      "Epoch 357/500\n",
      "80/80 - 0s - loss: 0.5815 - accuracy: 0.6855\n",
      "Epoch 358/500\n",
      "80/80 - 0s - loss: 0.5816 - accuracy: 0.6847\n",
      "Epoch 359/500\n",
      "80/80 - 0s - loss: 0.5830 - accuracy: 0.6847\n",
      "Epoch 360/500\n",
      "80/80 - 0s - loss: 0.5821 - accuracy: 0.6749\n",
      "Epoch 361/500\n",
      "80/80 - 0s - loss: 0.5829 - accuracy: 0.6816\n",
      "Epoch 362/500\n",
      "80/80 - 0s - loss: 0.5827 - accuracy: 0.6769\n",
      "Epoch 363/500\n",
      "80/80 - 0s - loss: 0.5820 - accuracy: 0.6753\n",
      "Epoch 364/500\n",
      "80/80 - 0s - loss: 0.5824 - accuracy: 0.6832\n",
      "Epoch 365/500\n",
      "80/80 - 0s - loss: 0.5831 - accuracy: 0.6836\n",
      "Epoch 366/500\n",
      "80/80 - 0s - loss: 0.5837 - accuracy: 0.6820\n",
      "Epoch 367/500\n",
      "80/80 - 0s - loss: 0.5827 - accuracy: 0.6769\n",
      "Epoch 368/500\n",
      "80/80 - 0s - loss: 0.5824 - accuracy: 0.6800\n",
      "Epoch 369/500\n",
      "80/80 - 0s - loss: 0.5819 - accuracy: 0.6777\n",
      "Epoch 370/500\n",
      "80/80 - 0s - loss: 0.5824 - accuracy: 0.6800\n",
      "Epoch 371/500\n",
      "80/80 - 0s - loss: 0.5818 - accuracy: 0.6804\n",
      "Epoch 372/500\n",
      "80/80 - 0s - loss: 0.5817 - accuracy: 0.6789\n",
      "Epoch 373/500\n",
      "80/80 - 0s - loss: 0.5815 - accuracy: 0.6792\n",
      "Epoch 374/500\n",
      "80/80 - 0s - loss: 0.5820 - accuracy: 0.6789\n",
      "Epoch 375/500\n",
      "80/80 - 0s - loss: 0.5812 - accuracy: 0.6792\n",
      "Epoch 376/500\n",
      "80/80 - 0s - loss: 0.5815 - accuracy: 0.6836\n",
      "Epoch 377/500\n",
      "80/80 - 0s - loss: 0.5824 - accuracy: 0.6840\n",
      "Epoch 378/500\n",
      "80/80 - 0s - loss: 0.5812 - accuracy: 0.6789\n",
      "Epoch 379/500\n",
      "80/80 - 0s - loss: 0.5816 - accuracy: 0.6792\n",
      "Epoch 380/500\n",
      "80/80 - 0s - loss: 0.5816 - accuracy: 0.6792\n",
      "Epoch 381/500\n",
      "80/80 - 0s - loss: 0.5828 - accuracy: 0.6808\n",
      "Epoch 382/500\n",
      "80/80 - 0s - loss: 0.5811 - accuracy: 0.6792\n",
      "Epoch 383/500\n",
      "80/80 - 0s - loss: 0.5813 - accuracy: 0.6816\n",
      "Epoch 384/500\n",
      "80/80 - 0s - loss: 0.5813 - accuracy: 0.6769\n",
      "Epoch 385/500\n",
      "80/80 - 0s - loss: 0.5813 - accuracy: 0.6867\n",
      "Epoch 386/500\n",
      "80/80 - 0s - loss: 0.5808 - accuracy: 0.6816\n",
      "Epoch 387/500\n",
      "80/80 - 0s - loss: 0.5812 - accuracy: 0.6855\n",
      "Epoch 388/500\n",
      "80/80 - 0s - loss: 0.5806 - accuracy: 0.6840\n",
      "Epoch 389/500\n",
      "80/80 - 0s - loss: 0.5807 - accuracy: 0.6789\n",
      "Epoch 390/500\n",
      "80/80 - 0s - loss: 0.5803 - accuracy: 0.6816\n",
      "Epoch 391/500\n",
      "80/80 - 0s - loss: 0.5809 - accuracy: 0.6781\n",
      "Epoch 392/500\n",
      "80/80 - 0s - loss: 0.5807 - accuracy: 0.6812\n",
      "Epoch 393/500\n",
      "80/80 - 0s - loss: 0.5805 - accuracy: 0.6785\n",
      "Epoch 394/500\n",
      "80/80 - 0s - loss: 0.5809 - accuracy: 0.6816\n",
      "Epoch 395/500\n",
      "80/80 - 0s - loss: 0.5803 - accuracy: 0.6785\n",
      "Epoch 396/500\n",
      "80/80 - 0s - loss: 0.5814 - accuracy: 0.6792\n",
      "Epoch 397/500\n",
      "80/80 - 0s - loss: 0.5814 - accuracy: 0.6847\n",
      "Epoch 398/500\n",
      "80/80 - 0s - loss: 0.5803 - accuracy: 0.6832\n",
      "Epoch 399/500\n",
      "80/80 - 0s - loss: 0.5802 - accuracy: 0.6832\n",
      "Epoch 400/500\n",
      "80/80 - 0s - loss: 0.5800 - accuracy: 0.6836\n",
      "Epoch 401/500\n",
      "80/80 - 0s - loss: 0.5801 - accuracy: 0.6816\n",
      "Epoch 402/500\n",
      "80/80 - 0s - loss: 0.5801 - accuracy: 0.6761\n",
      "Epoch 403/500\n",
      "80/80 - 0s - loss: 0.5797 - accuracy: 0.6828\n",
      "Epoch 404/500\n",
      "80/80 - 0s - loss: 0.5807 - accuracy: 0.6824\n",
      "Epoch 405/500\n",
      "80/80 - 0s - loss: 0.5796 - accuracy: 0.6816\n",
      "Epoch 406/500\n",
      "80/80 - 0s - loss: 0.5804 - accuracy: 0.6804\n",
      "Epoch 407/500\n",
      "80/80 - 0s - loss: 0.5812 - accuracy: 0.6812\n",
      "Epoch 408/500\n",
      "80/80 - 0s - loss: 0.5801 - accuracy: 0.6867\n",
      "Epoch 409/500\n",
      "80/80 - 0s - loss: 0.5792 - accuracy: 0.6816\n",
      "Epoch 410/500\n",
      "80/80 - 0s - loss: 0.5799 - accuracy: 0.6804\n",
      "Epoch 411/500\n",
      "80/80 - 0s - loss: 0.5796 - accuracy: 0.6820\n",
      "Epoch 412/500\n",
      "80/80 - 0s - loss: 0.5798 - accuracy: 0.6875\n",
      "Epoch 413/500\n",
      "80/80 - 0s - loss: 0.5790 - accuracy: 0.6847\n",
      "Epoch 414/500\n",
      "80/80 - 0s - loss: 0.5792 - accuracy: 0.6828\n",
      "Epoch 415/500\n",
      "80/80 - 0s - loss: 0.5800 - accuracy: 0.6804\n",
      "Epoch 416/500\n",
      "80/80 - 0s - loss: 0.5790 - accuracy: 0.6812\n",
      "Epoch 417/500\n",
      "80/80 - 0s - loss: 0.5793 - accuracy: 0.6769\n",
      "Epoch 418/500\n",
      "80/80 - 0s - loss: 0.5793 - accuracy: 0.6800\n",
      "Epoch 419/500\n",
      "80/80 - 0s - loss: 0.5789 - accuracy: 0.6832\n",
      "Epoch 420/500\n",
      "80/80 - 0s - loss: 0.5788 - accuracy: 0.6812\n",
      "Epoch 421/500\n",
      "80/80 - 0s - loss: 0.5784 - accuracy: 0.6812\n",
      "Epoch 422/500\n",
      "80/80 - 0s - loss: 0.5787 - accuracy: 0.6816\n",
      "Epoch 423/500\n",
      "80/80 - 0s - loss: 0.5786 - accuracy: 0.6789\n",
      "Epoch 424/500\n",
      "80/80 - 0s - loss: 0.5786 - accuracy: 0.6757\n",
      "Epoch 425/500\n",
      "80/80 - 0s - loss: 0.5788 - accuracy: 0.6863\n",
      "Epoch 426/500\n",
      "80/80 - 0s - loss: 0.5792 - accuracy: 0.6800\n",
      "Epoch 427/500\n",
      "80/80 - 0s - loss: 0.5792 - accuracy: 0.6804\n",
      "Epoch 428/500\n",
      "80/80 - 0s - loss: 0.5779 - accuracy: 0.6804\n",
      "Epoch 429/500\n",
      "80/80 - 0s - loss: 0.5787 - accuracy: 0.6903\n",
      "Epoch 430/500\n",
      "80/80 - 0s - loss: 0.5783 - accuracy: 0.6769\n",
      "Epoch 431/500\n",
      "80/80 - 0s - loss: 0.5782 - accuracy: 0.6879\n",
      "Epoch 432/500\n",
      "80/80 - 0s - loss: 0.5774 - accuracy: 0.6812\n",
      "Epoch 433/500\n",
      "80/80 - 0s - loss: 0.5795 - accuracy: 0.6800\n",
      "Epoch 434/500\n",
      "80/80 - 0s - loss: 0.5780 - accuracy: 0.6828\n",
      "Epoch 435/500\n",
      "80/80 - 0s - loss: 0.5777 - accuracy: 0.6816\n",
      "Epoch 436/500\n",
      "80/80 - 0s - loss: 0.5777 - accuracy: 0.6804\n",
      "Epoch 437/500\n",
      "80/80 - 0s - loss: 0.5777 - accuracy: 0.6777\n",
      "Epoch 438/500\n",
      "80/80 - 0s - loss: 0.5778 - accuracy: 0.6847\n",
      "Epoch 439/500\n",
      "80/80 - 0s - loss: 0.5778 - accuracy: 0.6828\n",
      "Epoch 440/500\n",
      "80/80 - 0s - loss: 0.5787 - accuracy: 0.6773\n",
      "Epoch 441/500\n",
      "80/80 - 0s - loss: 0.5771 - accuracy: 0.6832\n",
      "Epoch 442/500\n",
      "80/80 - 0s - loss: 0.5784 - accuracy: 0.6808\n",
      "Epoch 443/500\n",
      "80/80 - 0s - loss: 0.5775 - accuracy: 0.6769\n",
      "Epoch 444/500\n",
      "80/80 - 0s - loss: 0.5776 - accuracy: 0.6796\n",
      "Epoch 445/500\n",
      "80/80 - 0s - loss: 0.5772 - accuracy: 0.6765\n",
      "Epoch 446/500\n",
      "80/80 - 0s - loss: 0.5770 - accuracy: 0.6832\n",
      "Epoch 447/500\n",
      "80/80 - 0s - loss: 0.5771 - accuracy: 0.6785\n",
      "Epoch 448/500\n",
      "80/80 - 0s - loss: 0.5771 - accuracy: 0.6828\n",
      "Epoch 449/500\n",
      "80/80 - 0s - loss: 0.5768 - accuracy: 0.6883\n",
      "Epoch 450/500\n",
      "80/80 - 0s - loss: 0.5770 - accuracy: 0.6863\n",
      "Epoch 451/500\n",
      "80/80 - 0s - loss: 0.5767 - accuracy: 0.6883\n",
      "Epoch 452/500\n",
      "80/80 - 0s - loss: 0.5775 - accuracy: 0.6828\n",
      "Epoch 453/500\n",
      "80/80 - 0s - loss: 0.5760 - accuracy: 0.6840\n",
      "Epoch 454/500\n",
      "80/80 - 0s - loss: 0.5769 - accuracy: 0.6808\n",
      "Epoch 455/500\n",
      "80/80 - 0s - loss: 0.5768 - accuracy: 0.6851\n",
      "Epoch 456/500\n",
      "80/80 - 0s - loss: 0.5774 - accuracy: 0.6761\n",
      "Epoch 457/500\n",
      "80/80 - 0s - loss: 0.5775 - accuracy: 0.6851\n",
      "Epoch 458/500\n",
      "80/80 - 0s - loss: 0.5760 - accuracy: 0.6765\n",
      "Epoch 459/500\n",
      "80/80 - 0s - loss: 0.5758 - accuracy: 0.6812\n",
      "Epoch 460/500\n",
      "80/80 - 0s - loss: 0.5765 - accuracy: 0.6789\n",
      "Epoch 461/500\n",
      "80/80 - 0s - loss: 0.5759 - accuracy: 0.6804\n",
      "Epoch 462/500\n",
      "80/80 - 0s - loss: 0.5769 - accuracy: 0.6804\n",
      "Epoch 463/500\n",
      "80/80 - 0s - loss: 0.5757 - accuracy: 0.6804\n",
      "Epoch 464/500\n",
      "80/80 - 0s - loss: 0.5758 - accuracy: 0.6789\n",
      "Epoch 465/500\n",
      "80/80 - 0s - loss: 0.5759 - accuracy: 0.6820\n",
      "Epoch 466/500\n",
      "80/80 - 0s - loss: 0.5758 - accuracy: 0.6777\n",
      "Epoch 467/500\n",
      "80/80 - 0s - loss: 0.5766 - accuracy: 0.6785\n",
      "Epoch 468/500\n",
      "80/80 - 0s - loss: 0.5759 - accuracy: 0.6804\n",
      "Epoch 469/500\n",
      "80/80 - 0s - loss: 0.5758 - accuracy: 0.6804\n",
      "Epoch 470/500\n",
      "80/80 - 0s - loss: 0.5762 - accuracy: 0.6773\n",
      "Epoch 471/500\n",
      "80/80 - 0s - loss: 0.5751 - accuracy: 0.6769\n",
      "Epoch 472/500\n",
      "80/80 - 0s - loss: 0.5752 - accuracy: 0.6800\n",
      "Epoch 473/500\n",
      "80/80 - 0s - loss: 0.5751 - accuracy: 0.6749\n",
      "Epoch 474/500\n",
      "80/80 - 0s - loss: 0.5758 - accuracy: 0.6816\n",
      "Epoch 475/500\n",
      "80/80 - 0s - loss: 0.5766 - accuracy: 0.6773\n",
      "Epoch 476/500\n",
      "80/80 - 0s - loss: 0.5754 - accuracy: 0.6789\n",
      "Epoch 477/500\n",
      "80/80 - 0s - loss: 0.5762 - accuracy: 0.6761\n",
      "Epoch 478/500\n",
      "80/80 - 0s - loss: 0.5744 - accuracy: 0.6828\n",
      "Epoch 479/500\n",
      "80/80 - 0s - loss: 0.5741 - accuracy: 0.6796\n",
      "Epoch 480/500\n",
      "80/80 - 0s - loss: 0.5757 - accuracy: 0.6867\n",
      "Epoch 481/500\n",
      "80/80 - 0s - loss: 0.5745 - accuracy: 0.6808\n",
      "Epoch 482/500\n",
      "80/80 - 0s - loss: 0.5757 - accuracy: 0.6804\n",
      "Epoch 483/500\n",
      "80/80 - 0s - loss: 0.5748 - accuracy: 0.6777\n",
      "Epoch 484/500\n",
      "80/80 - 0s - loss: 0.5741 - accuracy: 0.6789\n",
      "Epoch 485/500\n",
      "80/80 - 0s - loss: 0.5757 - accuracy: 0.6757\n",
      "Epoch 486/500\n",
      "80/80 - 0s - loss: 0.5745 - accuracy: 0.6808\n",
      "Epoch 487/500\n",
      "80/80 - 0s - loss: 0.5744 - accuracy: 0.6773\n",
      "Epoch 488/500\n",
      "80/80 - 0s - loss: 0.5749 - accuracy: 0.6800\n",
      "Epoch 489/500\n",
      "80/80 - 0s - loss: 0.5735 - accuracy: 0.6828\n",
      "Epoch 490/500\n",
      "80/80 - 0s - loss: 0.5753 - accuracy: 0.6765\n",
      "Epoch 491/500\n",
      "80/80 - 0s - loss: 0.5746 - accuracy: 0.6808\n",
      "Epoch 492/500\n",
      "80/80 - 0s - loss: 0.5750 - accuracy: 0.6820\n",
      "Epoch 493/500\n",
      "80/80 - 0s - loss: 0.5755 - accuracy: 0.6804\n",
      "Epoch 494/500\n",
      "80/80 - 0s - loss: 0.5746 - accuracy: 0.6749\n",
      "Epoch 495/500\n",
      "80/80 - 0s - loss: 0.5737 - accuracy: 0.6769\n",
      "Epoch 496/500\n",
      "80/80 - 0s - loss: 0.5748 - accuracy: 0.6847\n",
      "Epoch 497/500\n",
      "80/80 - 0s - loss: 0.5742 - accuracy: 0.6812\n",
      "Epoch 498/500\n",
      "80/80 - 0s - loss: 0.5733 - accuracy: 0.6781\n",
      "Epoch 499/500\n",
      "80/80 - 0s - loss: 0.5735 - accuracy: 0.6828\n",
      "Epoch 500/500\n",
      "80/80 - 0s - loss: 0.5735 - accuracy: 0.6824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25f0ed9dfd0>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\r\n",
    "# get model\r\n",
    "model = get_model(11, 1)\r\n",
    "# fit the model on all data\r\n",
    "model.fit(X_resampled, y_resampled, verbose=2, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 - 0s - loss: 0.5617 - accuracy: 0.8174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5617128610610962, 0.817427396774292]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.evaluate(X_test,y_test, verbose=2)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = model.predict(X_test)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rounded = [round(x[0]) for x in y_pred]\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-196-80b1d648d7bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Display the confusion matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Create a DataFrame from the confusion matrix.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m cm_df = pd.DataFrame(\n",
      "\u001b[1;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "# Display the confusion matrix\r\n",
    "cm = confusion_matrix(y_test, y_pred)\r\n",
    "\r\n",
    "# Create a DataFrame from the confusion matrix.\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\r\n",
    "\r\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = [3, 3, 6, 7, 8, 2, 11, 11, 1, 3]\r\n",
    "newX = asarray([row])\r\n",
    "yhat = model.predict(newX)\r\n",
    "print('Predicted: %s' % yhat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = [3, 3, 6, 7, 8, 2, 11, 11, 1, 3]\r\n",
    "newX = asarray([row])\r\n",
    "yhat = model.predict(newX)\r\n",
    "print('Predicted: %s' % yhat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian probability distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 225, 244, 209, 217, 252, 261, 180, 193, 136, 2]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rounding to integer so you can create bins\r\n",
    "rounded_column = hist_df[\"W\"]\r\n",
    "rounded_column2 = [round(value) for value in rounded_column]\r\n",
    "rounded_column2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an array with sign positions repeated \"weight\" number of times\r\n",
    "for i in range(0, 10):\r\n",
    "    a = np.empty(rounded_column2[i], dtype=object)\r\n",
    "    a.fill(i)\r\n",
    "    array.extend(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1931"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.array(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate a sample\r\n",
    "sample = array\r\n",
    "# fit density\r\n",
    "model = KernelDensity(bandwidth=2, kernel='gaussian')\r\n",
    "sample = sample.reshape((len(sample), 1))\r\n",
    "model.fit(sample)\r\n",
    "# sample probabilities for a range of outcomes\r\n",
    "values = asarray([value for value in range(0, 10)])\r\n",
    "values = values.reshape((len(values), 1))\r\n",
    "probabilities = model.score_samples(values)\r\n",
    "probabilities = exp(probabilities)\r\n",
    "# plot the histogram and pdf\r\n",
    "plt.hist(sample, bins=10, density=True)\r\n",
    "plt.plot(values[:], probabilities)\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0487791026735262"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities[0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "acf47b83519c56191d0c3841e12beeb775e3446d2e4f4edc07386d3a55ce7a5e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}