{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: delayed in c:\\users\\keetu\\anaconda3\\lib\\site-packages (0.11.0b1)\n",
      "Requirement already satisfied: hiredis in c:\\users\\keetu\\anaconda3\\lib\\site-packages (from delayed) (2.0.0)\n",
      "Requirement already satisfied: redis in c:\\users\\keetu\\anaconda3\\lib\\site-packages (from delayed) (3.5.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing dependencies\r\n",
    "from sqlalchemy import create_engine\r\n",
    "from config import db_password\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from numpy.random import normal\r\n",
    "from numpy import hstack\r\n",
    "from numpy import asarray\r\n",
    "from numpy import exp\r\n",
    "from sklearn.neighbors import KernelDensity\r\n",
    "import numpy as np\r\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\r\n",
    "from imblearn.metrics import classification_report_imbalanced\r\n",
    "from imblearn.over_sampling import RandomOverSampler\r\n",
    "from numpy import asarray\r\n",
    "from sklearn.datasets import make_multilabel_classification\r\n",
    "from keras.models import Sequential\r\n",
    "from keras.layers import Dense\r\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating connection string\r\n",
    "db_string = f\"postgres://postgres:{db_password}@indusscript.cljludlfcgoa.us-east-2.rds.amazonaws.com:5432/postgres\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting Dataframe display to max\r\n",
    "pd.set_option('display.max_rows', None)\r\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating engine\r\n",
    "engine = create_engine(db_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000-5001 1094 5177-5002 5003-5004-5178-5005-5006-4034-4008 5007-5002-4017 5008-5181-4039 ( 2000 ) 2001 2002-4006-4001-4001-1155 2003 5011-5004-4001-5178 2004 1060 2005-5182-4008 2006-4025-4033 2007-5178 1103 2008 4025-5004-5012-5013-5014 2009-4021-1040 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2559 2011-5131 , 2625 2012 2013-4022 2014 : .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015 1014 2001-4033 2016-4008 2017-4039 2018-5178 2019-5182-4000-4025 2020-4008 2021-5186-4039 , 2022 2023-5187-4012-4008 1115 2001 2002-5187-4012-4000 2024-4031-1138 , 2025-5131 2026 2001 2002-5187-4012-4000 2027-4025-4031-1138 2028 2029 2030 2031-4021-4006 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2032 , 5005-4006-5014-5015 , 5016-5178-5017 , 5018-5181-4025-5019 , 5000-5001 2033-4020 2001 2002-5187-4012-4000 2034 2035 2036-5187-4012 2037-4025-4033-1090 2038-4033 2007-4035-4017 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2880-4021-4008-1138 , 2039-4021-4008-1138 5007-5002-4017 5008-5181-4039 2001 2002-5187-4012-4000 2027-4006 2500-4021-4000 2040-5133 2021-5186-4039 2041-4022-4017-4034 .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                               Sentence\n",
       "0       5000-5001 1094 5177-5002 5003-5004-5178-5005-5006-4034-4008 5007-5002-4017 5008-5181-4039 ( 2000 ) 2001 2002-4006-4001-4001-1155 2003 5011-5004-4001-5178 2004 1060 2005-5182-4008 2006-4025-4033 2007-5178 1103 2008 4025-5004-5012-5013-5014 2009-4021-1040 .\n",
       "1                                                                                                                                                                                                                         2559 2011-5131 , 2625 2012 2013-4022 2014 : .\n",
       "2  2015 1014 2001-4033 2016-4008 2017-4039 2018-5178 2019-5182-4000-4025 2020-4008 2021-5186-4039 , 2022 2023-5187-4012-4008 1115 2001 2002-5187-4012-4000 2024-4031-1138 , 2025-5131 2026 2001 2002-5187-4012-4000 2027-4025-4031-1138 2028 2029 2030 2031-4021-4006 .\n",
       "3                                                                              2032 , 5005-4006-5014-5015 , 5016-5178-5017 , 5018-5181-4025-5019 , 5000-5001 2033-4020 2001 2002-5187-4012-4000 2034 2035 2036-5187-4012 2037-4025-4033-1090 2038-4033 2007-4035-4017 .\n",
       "4                                                                                              2880-4021-4008-1138 , 2039-4021-4008-1138 5007-5002-4017 5008-5181-4039 2001 2002-5187-4012-4000 2027-4006 2500-4021-4000 2040-5133 2021-5186-4039 2041-4022-4017-4034 ."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading logosyllabic sentences data from postgreSQL\r\n",
    "logosyllabic_sentence_df = pd.read_sql_table('logo_syllabic_tamil_sentences', con=engine)\r\n",
    "logosyllabic_sentence_df.drop(columns=\"index\", inplace=True)\r\n",
    "logosyllabic_sentence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = ['0','1','2','3','4','5','6','7','8','9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Position</th>\n",
       "      <th>Index</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Sentence, Position, Index, Word]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sign_position_df = pd.DataFrame(columns =['Sentence', 'Position', 'Index', 'Word'])\r\n",
    "sign_position_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "for l in range(len(logosyllabic_sentence_df[\"Sentence\"])):\r\n",
    "    count = 0\r\n",
    "    indexes =[]\r\n",
    "    try:\r\n",
    "        for i in range(len(logosyllabic_sentence_df.loc[l, \"Sentence\"])):\r\n",
    "            if (logosyllabic_sentence_df.loc[l, \"Sentence\"][i] in numbers) and (logosyllabic_sentence_df.loc[l, \"Sentence\"][i+1] in numbers) and (logosyllabic_sentence_df.loc[l, \"Sentence\"][i-1] not in numbers):\r\n",
    "                count = count+1\r\n",
    "                length = len(sign_position_df)\r\n",
    "                sign_position_df.loc[length, \"Sentence\"] = l\r\n",
    "                sign_position_df.loc[length, \"Position\"] = count\r\n",
    "                sign_position_df.loc[length, \"Index\"] = i\r\n",
    "                letter =[]\r\n",
    "                for k in range(6):\r\n",
    "                    if logosyllabic_sentence_df.loc[l, \"Sentence\"][i+k] in numbers:\r\n",
    "                        letter.append(logosyllabic_sentence_df.loc[l, \"Sentence\"][i+k])\r\n",
    "                    else:\r\n",
    "                        word = ''.join(letter)\r\n",
    "                        #print(word)\r\n",
    "                        sign_position_df.loc[length, \"Word\"] = word\r\n",
    "    except:\r\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_position_df[\"MINP\"]=0\r\n",
    "sign_position_df[\"MAXP\"]=0\r\n",
    "sign_position_df[\"AVGP\"]=0\r\n",
    "sign_position_df[\"W\"]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-da98fbc963c6>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sliced_df[\"index\"]=sliced_df.index\n",
      "C:\\Users\\keetu\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "C:\\Users\\keetu\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(logosyllabic_sentence_df)-1):\r\n",
    "    sliced_df = sign_position_df[sign_position_df[\"Sentence\"]==i]\r\n",
    "    sliced_df[\"index\"]=sliced_df.index\r\n",
    "    sliced_df.reset_index(drop=True, inplace=True)\r\n",
    "    L = sliced_df.loc[(len(sliced_df)-1), \"Position\"]\r\n",
    "    NL = 10\r\n",
    "    W = L/NL\r\n",
    "    sliced_df.loc[:, \"MINP\"] = (sliced_df.loc[:, \"Position\"]-1)*NL/L\r\n",
    "    sliced_df.loc[:, \"MAXP\"] = (sliced_df.loc[:, \"Position\"]*NL/L)\r\n",
    "    sliced_df.W = W\r\n",
    "    mask = sliced_df[\"index\"]\r\n",
    "    sliced_df.index=sliced_df[\"index\"]\r\n",
    "    sign_position_df.loc[mask, [\"MINP\", \"MAXP\", \"W\"]]= sliced_df.loc[:, [\"MINP\", \"MAXP\", \"W\"]]\r\n",
    "\r\n",
    "sign_position_df['AVGP'] = sign_position_df[['MINP', 'MAXP']].mean(axis=1)\r\n",
    "sign_position_df.AVGP = sign_position_df.AVGP.apply(lambda x: round(x))\r\n",
    "sign_position_df.MINP = sign_position_df.MINP.apply(lambda x: round(x))\r\n",
    "sign_position_df.MAXP = sign_position_df.MAXP.apply(lambda x: round(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Position</th>\n",
       "      <th>Index</th>\n",
       "      <th>Word</th>\n",
       "      <th>MINP</th>\n",
       "      <th>MAXP</th>\n",
       "      <th>AVGP</th>\n",
       "      <th>W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1094</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>5177</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>5002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentence Position Index  Word  MINP  MAXP  AVGP    W\n",
       "0        0        1     0  5000     0     0     0  5.0\n",
       "1        0        2     5  5001     0     0     0  5.0\n",
       "2        0        3    10  1094     0     1     0  5.0\n",
       "3        0        4    15  5177     1     1     1  5.0\n",
       "4        0        5    20  5002     1     1     1  5.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sign_position_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sign_position_df[\"Word\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating probability distribution as features of Machine Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>initial</th>\n",
       "      <th>medial</th>\n",
       "      <th>terminal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Word, initial, medial, terminal]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df = pd.DataFrame(columns=['Word', 'initial', 'medial', 'terminal'])\r\n",
    "word_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sign_position_df)):\r\n",
    "    try:\r\n",
    "        temp_df = sign_position_df[sign_position_df[\"Word\"]==words[i]]\r\n",
    "        temp_df.reset_index(drop=True, inplace=True)\r\n",
    "        hist_df = temp_df[['Word','AVGP','W']].groupby(by=[\"Word\",\"AVGP\"]).sum()\r\n",
    "        hist_df.reset_index(inplace=True)\r\n",
    "        hist_df[\"Probability\"] = hist_df[\"W\"]/sum(hist_df[\"W\"])\r\n",
    "        \r\n",
    "        length = len(word_df)\r\n",
    "        word_df.loc[length, \"Word\"] = hist_df.loc[0, \"Word\"]\r\n",
    "        word_df.loc[length, \"initial\"] = 0\r\n",
    "        word_df.loc[length, \"medial\"] = 0\r\n",
    "        word_df.loc[length, \"terminal\"] = 0\r\n",
    "        try:\r\n",
    "            word_df.loc[length, \"initial\"] = word_df.loc[length, \"initial\"] + hist_df.loc[0, \"Probability\"]\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "        try:\r\n",
    "            word_df.loc[length, \"initial\"] = word_df.loc[length, \"initial\"] + hist_df.loc[1, \"Probability\"]\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "        try:\r\n",
    "            word_df.loc[length, \"initial\"] = word_df.loc[length, \"initial\"] + hist_df.loc[2, \"Probability\"]\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "        try:\r\n",
    "            word_df.loc[length, \"initial\"] = word_df.loc[length, \"initial\"] + hist_df.loc[3, \"Probability\"]\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "        try:\r\n",
    "            word_df.loc[length, \"medial\"] = word_df.loc[length, \"initial\"] + hist_df.loc[4, \"Probability\"]\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "        try:\r\n",
    "            word_df.loc[length, \"medial\"] = word_df.loc[length, \"initial\"] + hist_df.loc[5, \"Probability\"]\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "        try:\r\n",
    "            word_df.loc[length, \"medial\"] = word_df.loc[length, \"initial\"] + hist_df.loc[6, \"Probability\"]\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "        try:\r\n",
    "            word_df.loc[length, \"terminal\"] = word_df.loc[length, \"initial\"] + hist_df.loc[7, \"Probability\"]\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "        try:\r\n",
    "            word_df.loc[length, \"terminal\"] = word_df.loc[length, \"initial\"] + hist_df.loc[8, \"Probability\"]\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "        try:\r\n",
    "            word_df.loc[length, \"terminal\"] = word_df.loc[length, \"initial\"] + hist_df.loc[9, \"Probability\"]\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "        try:\r\n",
    "            word_df.loc[length, \"terminal\"] = word_df.loc[length, \"initial\"] + hist_df.loc[10, \"Probability\"]\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "    except:\r\n",
    "        pass\r\n",
    "      \r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>initial</th>\n",
       "      <th>medial</th>\n",
       "      <th>terminal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.554217</td>\n",
       "      <td>0.61747</td>\n",
       "      <td>0.57756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5001</td>\n",
       "      <td>0.592089</td>\n",
       "      <td>0.640297</td>\n",
       "      <td>0.629172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1094</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5177</td>\n",
       "      <td>0.383367</td>\n",
       "      <td>0.476746</td>\n",
       "      <td>0.387926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5002</td>\n",
       "      <td>0.603806</td>\n",
       "      <td>0.775087</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Word   initial    medial  terminal\n",
       "0  5000  0.554217   0.61747   0.57756\n",
       "1  5001  0.592089  0.640297  0.629172\n",
       "2  1094         1         0         0\n",
       "3  5177  0.383367  0.476746  0.387926\n",
       "4  5002  0.603806  0.775087         0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>Adjectives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>Noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>Noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>Noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004</td>\n",
       "      <td>Noun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id        Type\n",
       "0  2000  Adjectives\n",
       "1  2001        Noun\n",
       "2  2002        Noun\n",
       "3  2003        Noun\n",
       "4  2004        Noun"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading lemmas from postgreSQL\r\n",
    "lemmas_df = pd.read_sql_table('lemmas_labelled', con=engine)\r\n",
    "lemmas_df.drop(columns=\"index\", inplace=True)\r\n",
    "lemmas_df = lemmas_df[[\"id\", \"Type\"]]\r\n",
    "lemmas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>Verb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>Verb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002</td>\n",
       "      <td>Particles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>Conjunctions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004</td>\n",
       "      <td>Verb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id          Type\n",
       "0  1000          Verb\n",
       "1  1001          Verb\n",
       "2  1002     Particles\n",
       "3  1003  Conjunctions\n",
       "4  1004          Verb"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading clitics from postgreSQL\r\n",
    "clitics_df = pd.read_sql_table('clitics_and_postpositions_labelled', con=engine)\r\n",
    "clitics_df.drop(columns=\"index\", inplace=True)\r\n",
    "clitics_df[\"id\"] = clitics_df[\"id\"].str.replace('-','')\r\n",
    "clitics_df = clitics_df[[\"id\", \"Type\"]]\r\n",
    "clitics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5131</td>\n",
       "      <td>Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4020</td>\n",
       "      <td>Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5133</td>\n",
       "      <td>Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4007</td>\n",
       "      <td>Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4008</td>\n",
       "      <td>Syllable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id      Type\n",
       "0  5131  Syllable\n",
       "1  4020  Syllable\n",
       "2  5133  Syllable\n",
       "3  4007  Syllable\n",
       "4  4008  Syllable"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading syllables from postgreSQL\r\n",
    "syllables_df = pd.read_sql_table('syllables', con=engine)\r\n",
    "syllables_df.drop(columns=\"index\", inplace=True)\r\n",
    "syllables_df[\"id\"] = syllables_df[\"id\"].str.replace('-','')\r\n",
    "syllables_df[\"Type\"] = \"Syllable\"\r\n",
    "syllables_df = syllables_df[[\"id\", \"Type\"]]\r\n",
    "syllables_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4035</td>\n",
       "      <td>Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4035</td>\n",
       "      <td>Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4018</td>\n",
       "      <td>Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4036</td>\n",
       "      <td>Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4036</td>\n",
       "      <td>Syllable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id      Type\n",
       "0  4035  Syllable\n",
       "1  4035  Syllable\n",
       "2  4018  Syllable\n",
       "3  4036  Syllable\n",
       "4  4036  Syllable"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading morphemes from postgreSQL\r\n",
    "morphemes_df = pd.read_sql_table('morphemes_labelled', con=engine)\r\n",
    "morphemes_df.drop(columns=\"index\", inplace=True)\r\n",
    "morphemes_df[\"id\"] = morphemes_df[\"id\"].str.replace('-','')\r\n",
    "\r\n",
    "morphemes_df = morphemes_df[[\"id\"]]\r\n",
    "morphemes_df[\"Type\"] = \"Syllable\"\r\n",
    "\r\n",
    "morphemes_df.dropna(inplace=True)\r\n",
    "morphemes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4035</td>\n",
       "      <td>Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4018</td>\n",
       "      <td>Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4036</td>\n",
       "      <td>Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4014</td>\n",
       "      <td>Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4040</td>\n",
       "      <td>Syllable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Word      Type\n",
       "0  4035  Syllable\n",
       "1  4018  Syllable\n",
       "2  4036  Syllable\n",
       "3  4014  Syllable\n",
       "4  4040  Syllable"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenating tables\r\n",
    "labelled_logos =  pd.concat([morphemes_df, syllables_df, clitics_df, lemmas_df])\r\n",
    "labelled_logos.reset_index(drop=True, inplace=True)\r\n",
    "labelled_logos.drop_duplicates(subset=\"id\", inplace=True)\r\n",
    "labelled_logos.reset_index(drop=True, inplace=True)\r\n",
    "labelled_logos.rename(columns = {\"id\": \"Word\"}, inplace=True)\r\n",
    "labelled_logos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>initial</th>\n",
       "      <th>medial</th>\n",
       "      <th>terminal</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>3532</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>3533</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>3534</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>3535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Syllable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>3536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Syllable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word  initial  medial  terminal          Type\n",
       "1920  3532      1.0     0.0       0.0  Not Syllable\n",
       "1921  3533      1.0     0.0       0.0  Not Syllable\n",
       "1922  3534      1.0     0.0       0.0  Not Syllable\n",
       "1923  3535      0.0     0.0       0.0  Not Syllable\n",
       "1924  3536      0.0     0.0       0.0  Not Syllable"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_word = word_df.merge(labelled_logos, on=\"Word\", how=\"left\")\r\n",
    "merged_word = merged_word.fillna(0)\r\n",
    "for i in range(len(merged_word[\"Type\"])):\r\n",
    "    if merged_word.loc[i, \"Type\"] != \"Syllable\":\r\n",
    "        merged_word.loc[i, \"Type\"] = \"Not Syllable\"\r\n",
    "merged_word.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type_Not Syllable</th>\n",
       "      <th>Type_Syllable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type_Not Syllable  Type_Syllable\n",
       "0                0.0            1.0\n",
       "1                0.0            1.0\n",
       "2                1.0            0.0\n",
       "3                0.0            1.0\n",
       "4                0.0            1.0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\r\n",
    "# Create a OneHotEncoder instance\r\n",
    "enc = OneHotEncoder(sparse=False)\r\n",
    "values = merged_word[\"Type\"].values\r\n",
    "values = values.reshape(-1,1)\r\n",
    "values = values.astype(str)\r\n",
    " \r\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\r\n",
    "encode_df = pd.DataFrame(enc.fit_transform(values))\r\n",
    "\r\n",
    "# Add the encoded variable names to the dataframe\r\n",
    "encode_df.columns = enc.get_feature_names([\"Type\"])\r\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>initial</th>\n",
       "      <th>medial</th>\n",
       "      <th>terminal</th>\n",
       "      <th>Type_Syllable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.554217</td>\n",
       "      <td>0.617470</td>\n",
       "      <td>0.577560</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5001</td>\n",
       "      <td>0.592089</td>\n",
       "      <td>0.640297</td>\n",
       "      <td>0.629172</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1094</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5177</td>\n",
       "      <td>0.383367</td>\n",
       "      <td>0.476746</td>\n",
       "      <td>0.387926</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5002</td>\n",
       "      <td>0.603806</td>\n",
       "      <td>0.775087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Word   initial    medial  terminal  Type_Syllable\n",
       "0  5000  0.554217  0.617470  0.577560            1.0\n",
       "1  5001  0.592089  0.640297  0.629172            1.0\n",
       "2  1094  1.000000  0.000000  0.000000            0.0\n",
       "3  5177  0.383367  0.476746  0.387926            1.0\n",
       "4  5002  0.603806  0.775087  0.000000            1.0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_word = merged_word.merge(encode_df,left_index=True, right_index=True)\r\n",
    "merged_word = merged_word.drop(columns=[\"Type\",\"Type_Not Syllable\"])\r\n",
    "merged_word.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228.0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_word[\"Type_Syllable\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1925"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_word[\"Type_Syllable\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "X = merged_word[[\"initial\", \"medial\", \"terminal\"]]\r\n",
    "X = np.asarray(X).astype('float32')\r\n",
    "y = merged_word.drop(columns=[\"Word\", \"initial\", \"medial\", \"terminal\"])\r\n",
    "y = np.asarray(y).astype('int')\r\n",
    "\r\n",
    "# Split the preprocessed data into a training and testing dataset\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=1)\r\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(n_inputs, n_outputs):\r\n",
    "\tmodel = Sequential()\r\n",
    "\tmodel.add(Dense(20, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\r\n",
    "\tmodel.add(Dense(n_outputs, activation='sigmoid'))\r\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\r\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "80/80 - 1s - loss: 0.7729 - accuracy: 0.4855\n",
      "Epoch 2/5\n",
      "80/80 - 0s - loss: 0.6808 - accuracy: 0.4870\n",
      "Epoch 3/5\n",
      "80/80 - 0s - loss: 0.6456 - accuracy: 0.6576\n",
      "Epoch 4/5\n",
      "80/80 - 0s - loss: 0.6313 - accuracy: 0.6639\n",
      "Epoch 5/5\n",
      "80/80 - 0s - loss: 0.6238 - accuracy: 0.6639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25f7e88ddf0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\r\n",
    "# get model\r\n",
    "model = get_model(3, 1)\r\n",
    "# fit the model on all data\r\n",
    "model.fit(X_resampled, y_resampled, verbose=2, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 - 0s - loss: 0.5855 - accuracy: 0.8195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5854899883270264, 0.819502055644989]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test, verbose=2)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded = [round(x[0]) for x in y_pred]\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.93      0.86      0.51      0.89      0.66      0.45       425\n",
      "          1       0.33      0.51      0.86      0.40      0.66      0.42        57\n",
      "\n",
      "avg / total       0.86      0.82      0.55      0.84      0.66      0.45       482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\r\n",
    "# Print the imbalanced classification report\r\n",
    "print(classification_report_imbalanced(y_test, rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\r\n",
    "cm = confusion_matrix(y_test, y_pred)\r\n",
    "\r\n",
    "# Create a DataFrame from the confusion matrix.\r\n",
    "cm_df = pd.DataFrame(\r\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\r\n",
    "\r\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = [3, 3, 6, 7, 8, 2, 11, 11, 1, 3]\r\n",
    "newX = asarray([row])\r\n",
    "yhat = model.predict(newX)\r\n",
    "print('Predicted: %s' % yhat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = [3, 3, 6, 7, 8, 2, 11, 11, 1, 3]\r\n",
    "newX = asarray([row])\r\n",
    "yhat = model.predict(newX)\r\n",
    "print('Predicted: %s' % yhat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian probability distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 225, 244, 209, 217, 252, 261, 180, 193, 136, 2]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rounding to integer so you can create bins\r\n",
    "rounded_column = hist_df[\"W\"]\r\n",
    "rounded_column2 = [round(value) for value in rounded_column]\r\n",
    "rounded_column2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an array with sign positions repeated \"weight\" number of times\r\n",
    "for i in range(0, 10):\r\n",
    "    a = np.empty(rounded_column2[i], dtype=object)\r\n",
    "    a.fill(i)\r\n",
    "    array.extend(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1931"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.array(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate a sample\r\n",
    "sample = array\r\n",
    "# fit density\r\n",
    "model = KernelDensity(bandwidth=2, kernel='gaussian')\r\n",
    "sample = sample.reshape((len(sample), 1))\r\n",
    "model.fit(sample)\r\n",
    "# sample probabilities for a range of outcomes\r\n",
    "values = asarray([value for value in range(0, 10)])\r\n",
    "values = values.reshape((len(values), 1))\r\n",
    "probabilities = model.score_samples(values)\r\n",
    "probabilities = exp(probabilities)\r\n",
    "# plot the histogram and pdf\r\n",
    "plt.hist(sample, bins=10, density=True)\r\n",
    "plt.plot(values[:], probabilities)\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0487791026735262"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities[0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "acf47b83519c56191d0c3841e12beeb775e3446d2e4f4edc07386d3a55ce7a5e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}